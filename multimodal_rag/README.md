# üé® Multimodal RAG Demo –∑ ChromaDB

–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è multimodal RAG —Å–∏—Å—Ç–µ–º–∏, —è–∫–∞ –ø—Ä–∞—Ü—é—î –∑ **—Ç–µ–∫—Å—Ç–æ–º + –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏** –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ ChromaDB.

**–Ü–Ω—Å–ø—ñ—Ä–æ–≤–∞–Ω–æ**: [Nano Banana Milvus Blog](https://milvus.io/blog/nano-banana-milvus-turning-hype-into-enterprise-ready-multimodal-rag.md)
**–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î**: ChromaDB (–ø—Ä–æ—Å—Ç—ñ—à–∏–π –∑–∞ Milvus –¥–ª—è –≤–æ—Ä–∫—à–æ–ø—ñ–≤)

---

## üéØ –©–æ –î–µ–º–æ–Ω—Å—Ç—Ä—É—î

### 1. **Multimodal Embeddings –∑ CLIP**
- –¢–µ–∫—Å—Ç —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ –æ–¥–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
- CLIP model: `clip-ViT-B-32` (512D embeddings)
- –°–µ–º–∞–Ω—Ç–∏—á–Ω–∞ –ø–æ–¥—ñ–±–Ω—ñ—Å—Ç—å –º—ñ–∂ text ‚Üî image

### 2. **ChromaDB –¥–ª—è –í–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ü–æ—à—É–∫—É**
- –õ–µ–≥–∫–∏–π —É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ (–±–µ–∑ —Å–∫–ª–∞–¥–Ω–æ–≥–æ setup)
- In-memory –¥–ª—è demo
- –®–≤–∏–¥–∫–∏–π –ø–æ—à—É–∫ nearest neighbors

### 3. **Cross-Modal Queries**
- üìù ‚Üí üñºÔ∏è –¢–µ–∫—Å—Ç–æ–≤–∏–π –∑–∞–ø–∏—Ç –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- üñºÔ∏è ‚Üí üìù –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π —Ç–µ–∫—Å—Ç
- üñºÔ∏è ‚Üí üñºÔ∏è –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å

---

## üöÄ –®–≤–∏–¥–∫–∏–π –°—Ç–∞—Ä—Ç

### –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

```bash
# 1. –ü–µ—Ä–µ–π—Ç–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
cd /Users/o.denysiuk/agents/module/2/rag_demos/multimodal_rag

# 2. –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
pip install chromadb sentence-transformers pillow torch

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ demo
python multimodal_rag_demo.py
```

### –©–æ –í—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è

```
chromadb              # –í–µ–∫—Ç–æ—Ä–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–∏—Ö
sentence-transformers # CLIP model
pillow                # Image processing
torch                 # PyTorch –¥–ª—è –º–æ–¥–µ–ª–µ–π
```

**–†–æ–∑–º—ñ—Ä –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è**: ~500MB (CLIP model)
**–ß–∞—Å –ø–µ—Ä—à–æ–≥–æ –∑–∞–ø—É—Å–∫—É**: 1-2 —Ö–≤–∏–ª–∏–Ω–∏ (–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ)

---

## üìä Demo Scenarios

### Demo 1: Fruit Recognition üçå
```python
# –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—Ä—É–∫—Ç–∏ (—Ç–µ–∫—Å—Ç + –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è)
banana_info = "Banana is a yellow tropical fruit, rich in potassium..."
apple_info = "Apple is a round fruit that comes in red, green..."

# –ü–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
query1 = "yellow tropical fruit rich in potassium"  # ‚Üí –∑–Ω–∞–π–¥–µ banana
query2 = "round citrus fruit with vitamin C"        # ‚Üí –∑–Ω–∞–π–¥–µ orange
query3 = "healthy fruit for breakfast"              # ‚Üí –∑–Ω–∞–π–¥–µ –≤—Å—ñ
```

**Use Case**: Product recognition –≤ retail/grocery

### Demo 2: E-Commerce Product Search üõí
```python
# –î–æ–¥–∞—î–º–æ –ø—Ä–æ–¥—É–∫—Ç–∏
laptop = "MacBook Pro 16-inch with M4 chip. Silver aluminum..."
chair = "Ergonomic office chair with lumbar support..."

# –ü–æ—à—É–∫
query1 = "powerful laptop for software development"  # ‚Üí MacBook/Dell
query2 = "Apple professional computer"               # ‚Üí MacBook
query3 = "comfortable chair for home office"         # ‚Üí Herman Miller
```

**Use Case**: E-commerce search, visual similarity

---

## üéì –î–ª—è –í–æ—Ä–∫—à–æ–ø—É

### –Ø–∫ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–∞ –í–æ—Ä–∫—à–æ–ø—ñ (7 —Ö–≤)

**–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞** (–∑–∞ –¥–µ–Ω—å –¥–æ):
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –æ–¥–∏–Ω —Ä–∞–∑ —â–æ–± –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
python multimodal_rag_demo.py
```

**–ù–∞ –≤–æ—Ä–∫—à–æ–ø—ñ:**

1. **–ü–æ—è—Å–Ω–∏—Ç–∏ –∫–æ–Ω—Ü–µ–ø—Ü—ñ—é** (2 —Ö–≤)
   - Multimodal = Text + Images –≤ –æ–¥–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
   - CLIP model –∫–æ–¥—É—î –æ–±–∏–¥–≤–∞ —Ç–∏–ø–∏ –¥–∞–Ω–∏—Ö –æ–¥–Ω–∞–∫–æ–≤–æ
   - –î–æ–∑–≤–æ–ª—è—î cross-modal search

2. **–ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ–¥** (2 —Ö–≤)
   ```python
   # –ö–ª—é—á–æ–≤—ñ —á–∞—Å—Ç–∏–Ω–∏:
   # 1. Encode text
   text_embedding = model.encode("banana fruit")

   # 2. Encode image
   image_embedding = model.encode(Image.open("banana.jpg"))

   # 3. –í–æ–Ω–∏ –≤ –æ–¥–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ! –ú–æ–∂–Ω–∞ –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏
   similarity = cosine_similarity(text_embedding, image_embedding)
   ```

3. **–ó–∞–ø—É—Å—Ç–∏—Ç–∏ demo** (3 —Ö–≤)
   ```bash
   python multimodal_rag_demo.py
   ```
   - –ü–æ–∫–∞–∂–µ –ø–æ—à—É–∫ —Ñ—Ä—É–∫—Ç—ñ–≤
   - –ü–æ–∫–∞–∂–µ e-commerce search
   - –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ similarity scores

---

## üí° –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input: Text Query –∞–±–æ Image                    ‚îÇ
‚îÇ  "yellow tropical fruit" –∞–±–æ banana.jpg         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  CLIP Encoder       ‚îÇ
        ‚îÇ  (clip-ViT-B-32)    ‚îÇ
        ‚îÇ                     ‚îÇ
        ‚îÇ  Text ‚Üí 512D vector ‚îÇ
        ‚îÇ  Image ‚Üí 512D vector‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  ChromaDB           ‚îÇ
        ‚îÇ  Vector Search      ‚îÇ
        ‚îÇ  k-NN (cosine)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Results:           ‚îÇ
        ‚îÇ  - Text docs        ‚îÇ
        ‚îÇ  - Images           ‚îÇ
        ‚îÇ  - Similarity scores‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –¥–ª—è Production

### –î–æ–¥–∞—Ç–∏ –°–ø—Ä–∞–≤–∂–Ω—ñ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è

```python
# 1. –°—Ç–≤–æ—Ä–∏—Ç–∏ images/ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
mkdir -p images

# 2. –î–æ–¥–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
# images/banana.jpg
# images/apple.jpg
# images/orange.jpg

# 3. –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –≤ –∫–æ–¥—ñ
rag.add_image_document(
    "banana_img",
    "images/banana.jpg",
    caption="A yellow curved banana"
)
```

### Image Preprocessing

```python
from PIL import Image

def preprocess_image(image_path, size=(224, 224)):
    """Resize —Ç–∞ normalize –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"""
    img = Image.open(image_path)
    img = img.resize(size)
    # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –æ–±—Ä–æ–±–∫–∞...
    return img
```

### Metadata Filtering

```python
# –ü–æ—à—É–∫ –ª–∏—à–µ –≤ –ø–µ–≤–Ω—ñ–π –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
results = rag.search_by_text(
    "laptop",
    n_results=5,
    where={"category": "electronics"}  # ChromaDB filtering
)
```

---

## üìà Use Cases

| Use Case | –û–ø–∏—Å | –ü—Ä–∏–∫–ª–∞–¥ |
|----------|------|---------|
| **E-Commerce** | –ü–æ—à—É–∫ —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ —Ñ–æ—Ç–æ –∞–±–æ –æ–ø–∏—Å–æ–º | "–ó–Ω–∞–π–¥–∏ —Å—Ö–æ–∂–∏–π —Å—Ç—ñ–ª–µ—Ü—å" |
| **Medical Imaging** | –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤ –∑–∞ —Å–Ω—ñ–º–∫–∞–º–∏ | X-ray ‚Üí –¥—ñ–∞–≥–Ω–æ–∑ + —ñ—Å—Ç–æ—Ä—ñ—è |
| **Fashion Retail** | –ü–æ—à—É–∫ –æ–¥—è–≥—É –∑–∞ —Ñ–æ—Ç–æ | –§–æ—Ç–æ outfit ‚Üí –¥–µ –∫—É–ø–∏—Ç–∏ |
| **Document Search** | –ü–æ—à—É–∫ –≤ PDF –∑ –¥—ñ–∞–≥—Ä–∞–º–∞–º–∏ | "–ó–Ω–∞–π–¥–∏ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ —Å—Ö–µ–º–∏" |
| **Social Media** | Content moderation, –ø–æ—à—É–∫ | –ó–Ω–∞–π—Ç–∏ —Å—Ö–æ–∂—ñ memes |

---

## ‚ö° Performance

### Benchmarks (Mac M4, 16GB)

```
Model loading:     ~2s (–ø–µ—Ä—à–∏–π —Ä–∞–∑)
Text encoding:     ~10ms
Image encoding:    ~50ms
Search (1K docs):  ~5ms
Total query:       ~65ms
```

### –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è

| Documents | Embeddings Size | Search Time |
|-----------|----------------|-------------|
| 1K        | 2MB            | 5ms         |
| 10K       | 20MB           | 15ms        |
| 100K      | 200MB          | 50ms        |
| 1M        | 2GB            | 200ms*      |

*–î–ª—è >100K –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ HNSW index –∞–±–æ Milvus

---

## üÜö ChromaDB vs Milvus

| Feature | ChromaDB | Milvus |
|---------|----------|--------|
| **Setup** | ‚úÖ –ü—Ä–æ—Å—Ç–∏–π (pip install) | ‚ö†Ô∏è Docker/K8s |
| **Use Case** | Prototypes, demos | Production, scale |
| **Scale** | < 1M vectors | Billions |
| **Features** | Basic | Advanced (sharding, replicas) |
| **–î–ª—è –≤–æ—Ä–∫—à–æ–ø—É** | ‚úÖ **–Ü–¥–µ–∞–ª—å–Ω–æ** | ‚ùå Overkill |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è –¥–ª—è –≤–æ—Ä–∫—à–æ–ø—É**: ChromaDB (–ø—Ä–æ—Å—Ç—ñ—à–µ, —à–≤–∏–¥—à–µ setup)
**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è –¥–ª—è production**: Milvus (—è–∫—â–æ >1M vectors)

---

## üêõ Troubleshooting

### –ü–æ–º–∏–ª–∫–∞: "No module named 'chromadb'"
```bash
pip install chromadb
```

### –ü–æ–º–∏–ª–∫–∞: "CLIP model download failed"
```bash
# Manually download
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('clip-ViT-B-32')
# –ë—É–¥–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤ ~/.cache/
```

### –ü–æ–≤—ñ–ª—å–Ω–∏–π –ø–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫
- –ù–æ—Ä–º–∞–ª—å–Ω–æ! CLIP model ~500MB
- –ù–∞—Å—Ç—É–ø–Ω—ñ –∑–∞–ø—É—Å–∫–∏ —à–≤–∏–¥–∫—ñ (–∫–µ—à—É—î—Ç—å—Å—è)

### –ü–æ–º–∏–ª–∫–∞ –∑ PIL/Pillow
```bash
pip install --upgrade pillow
```

---

## üìö –î–æ–¥–∞—Ç–∫–æ–≤—ñ –†–µ—Å—É—Ä—Å–∏

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
- [ChromaDB Docs](https://docs.trychroma.com/)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [Sentence Transformers](https://www.sbert.net/)

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –ú–æ–¥–µ–ª—ñ
```python
# –ö—Ä–∞—â—ñ –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω—ñ—à—ñ:
model = SentenceTransformer('clip-ViT-B-32')      # 512D, —à–≤–∏–¥–∫–æ
model = SentenceTransformer('clip-ViT-L-14')      # 768D, –∫—Ä–∞—â–µ
model = SentenceTransformer('clip-ViT-L-14-336')  # 768D, –Ω–∞–π–∫—Ä–∞—â–µ

# –î–ª—è production:
# - OpenCLIP variants
# - Custom fine-tuned models
```

---

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –¥–ª—è –í–æ—Ä–∫—à–æ–ø—É

**–ó–∞ –¥–µ–Ω—å –¥–æ**:
- [ ] –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ chromadb, sentence-transformers
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç–∏ `python multimodal_rag_demo.py` –æ–¥–∏–Ω —Ä–∞–∑
- [ ] –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è —â–æ CLIP model –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ
- [ ] (–û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ) –î–æ–¥–∞—Ç–∏ —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è

**–ù–∞ –≤–æ—Ä–∫—à–æ–ø—ñ**:
- [ ] –ü–æ—è—Å–Ω–∏—Ç–∏ –∫–æ–Ω—Ü–µ–ø—Ü—ñ—é multimodal embeddings
- [ ] –ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ–¥ (CLIP encoding)
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç–∏ demo (2 scenarios)
- [ ] –ü–æ–∫–∞–∑–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ similarity scores
- [ ] –ü–æ—è—Å–Ω–∏—Ç–∏ use cases

**–ß–∞—Å**: ~7 —Ö–≤–∏–ª–∏–Ω
**–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å**: –°–µ—Ä–µ–¥–Ω—è (–ø–æ—Ç—Ä–µ–±—É—î —Ä–æ–∑—É–º—ñ–Ω–Ω—è embeddings)

---

**–°—Ç–≤–æ—Ä–µ–Ω–æ**: 25 –∂–æ–≤—Ç–Ω—è 2025
**–î–ª—è**: RAG Workshop Module 2
**–ú–æ–≤–∞**: Python 3.11+

**–£—Å–ø—ñ—Ö—ñ–≤ –Ω–∞ –≤–æ—Ä–∫—à–æ–ø—ñ! üéâ**
