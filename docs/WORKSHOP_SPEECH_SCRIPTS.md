# üé§ –°—Ü–µ–Ω–∞—Ä—ñ—ó –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π –¥–ª—è RAG Workshop

**–í–æ—Ä–∫—à–æ–ø**: –ú–æ–¥—É–ª—å 2 - 7 –¢–∏–ø—ñ–≤ RAG –°–∏—Å—Ç–µ–º
**–î–∞—Ç–∞**: 30 –∂–æ–≤—Ç–Ω—è 2025, 18:30-21:00
**–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞**: 19:40-20:30 (50 —Ö–≤–∏–ª–∏–Ω)

---

## üìã –ó–∞–≥–∞–ª—å–Ω–∞ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ü—Ä–∞–∫—Ç–∏–∫–∏

```
–ë–ª–æ–∫ 1 (15 —Ö–≤): –ë–∞–∑–æ–≤—ñ RAG
‚îú‚îÄ‚îÄ Demo 1: Naive RAG (5 —Ö–≤)
‚îî‚îÄ‚îÄ Demo 2: Retrieve-and-Rerank (10 —Ö–≤)

–ë–ª–æ–∫ 2 (15 —Ö–≤): –ü—Ä–æ—Å—É–Ω—É—Ç—ñ RAG
‚îú‚îÄ‚îÄ Demo 3: Multimodal RAG (8 —Ö–≤)
‚îî‚îÄ‚îÄ Demo 4: Graph RAG (7 —Ö–≤)

–ë–ª–æ–∫ 3 (18 —Ö–≤): –ê–≥–µ–Ω—Ç–Ω—ñ RAG
‚îú‚îÄ‚îÄ Demo 5: Agentic Router (Self-RAG) (8 —Ö–≤)
‚îî‚îÄ‚îÄ Demo 6: Agentic Multi-Agent (10 —Ö–≤)

–ü—Ä–æ–ø—É—â–µ–Ω–æ: Hybrid RAG (–∑–≥–∞–¥–∞—Ç–∏ —Ç–µ–æ—Ä–µ—Ç–∏—á–Ω–æ –∞–±–æ –ø–æ–∫–∞–∑–∞—Ç–∏ —è–∫—â–æ –∑–∞–ª–∏—à–∏—Ç—å—Å—è —á–∞—Å)
```

---

# üé¨ –ë–õ–û–ö 1: –ë–∞–∑–æ–≤—ñ RAG (15 —Ö–≤–∏–ª–∏–Ω)

---

## Demo 1: Naive RAG (5 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ –Ω–∞–π–ø—Ä–æ—Å—Ç—ñ—à–∏–π RAG –ø—ñ–¥—Ö—ñ–¥ —ñ –π–æ–≥–æ –æ–±–º–µ–∂–µ–Ω–Ω—è

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ (–¥–æ –≤–æ—Ä–∫—à–æ–ø—É)
```bash
# Terminal 1 - —Ç—Ä–∏–º–∞—Ç–∏ –≥–æ—Ç–æ–≤–∏–º
cd /Users/o.denysiuk/agents/module/2
source rag_env/bin/activate
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1: –í—Å—Ç—É–ø (30 —Å–µ–∫)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ü–æ—á–∏–Ω–∞—î–º–æ –∑ –Ω–∞–π–ø—Ä–æ—Å—Ç—ñ—à–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É - Naive RAG. –¶–µ baseline, –≤—ñ–¥ —è–∫–æ–≥–æ –º–∏ –±—É–¥–µ–º–æ –≤—ñ–¥—à—Ç–æ–≤—Ö—É–≤–∞—Ç–∏—Å—è. –ó–∞—Ä–∞–∑ –ø–æ–±–∞—á–∏–º–æ —á–æ–º—É –≤—ñ–Ω –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è 'naive' —ñ —è–∫—ñ –≤ –Ω—å–æ–≥–æ –ø—Ä–æ–±–ª–µ–º–∏."

**–©–û –ü–û–ö–ê–ó–ê–¢–ò:**
- –í—ñ–¥–∫—Ä–∏—Ç–∏ `rag_demos/naive_rag/naive_rag_demo.py` –≤ VSCode
- –ü—Ä–æ–∫—Ä—É—Ç–∏—Ç–∏ –¥–æ –∫–ª–∞—Å—É `NaiveRAG` (—Ä—è–¥–∫–∏ 20-50)

**–©–û –°–ö–ê–ó–ê–¢–ò –ü–†–û –ö–û–î:**
> "–ü–æ–¥–∏–≤—ñ—Ç—å—Å—è –Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É: TF-IDF vectorizer –¥–ª—è –ø–æ—à—É–∫—É, –∫–æ—Å–∏–Ω—É—Å–Ω–∞ –ø–æ–¥—ñ–±–Ω—ñ—Å—Ç—å, —ñ –≤—Å–µ. –ù–µ–º–∞—î reranking, –Ω–µ–º–∞—î semantic embeddings - —á–∏—Å—Ç–æ keywords."

```python
# –ü–û–ö–ê–ó–ê–¢–ò –¶–ï–ô –§–†–ê–ì–ú–ï–ù–¢:
def retrieve(self, query: str, top_k: int = 5):
    query_vector = self.vectorizer.transform([query])
    similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]
    top_indices = np.argsort(similarities)[::-1][:top_k]
```

#### –•–≤–∏–ª–∏–Ω–∞ 2: –ó–∞–ø—É—Å–∫ Demo (1 —Ö–≤)
**–ö–û–ú–ê–ù–î–ê:**
```bash
python rag_demos/naive_rag/naive_rag_demo.py
```

**–©–û –ì–û–í–û–†–ò–¢–ò –ü–Ü–î –ß–ê–° –ó–ê–ü–£–°–ö–£:**
> "–ó–∞–ø—É—Å–∫–∞—é demo –∑ —Ç—Ä—å–æ–º–∞ —Ç–µ—Å—Ç–æ–≤–∏–º–∏ –∑–∞–ø–∏—Ç–∞–º–∏. –ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É –Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å - –≤–æ–Ω–∞ –±—É–¥–µ –≤–∏—Å–æ–∫–∞, –∞–ª–µ —è–∫—ñ—Å—Ç—å..."

**–û–ß–Ü–ö–£–í–ê–ù–ò–ô OUTPUT:**
```
üöÄ Naive RAG Demo
üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 10 –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
‚è±Ô∏è Retrieval: 15ms
üìù Query: "What is machine learning?"
‚úÖ Answer: ...
‚è±Ô∏è Total time: 2.6s
```

#### –•–≤–∏–ª–∏–Ω–∞ 3: –ê–Ω–∞–ª—ñ–∑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ (1.5 —Ö–≤)
**–©–û –ü–û–ö–ê–ó–ê–¢–ò:**
- –ü—Ä–æ–∫—Ä—É—Ç–∏—Ç–∏ output –¥–æ –ø–µ—Ä—à–æ–≥–æ –∑–∞–ø–∏—Ç—É
- –ó–≤–µ—Ä–Ω—É—Ç–∏ —É–≤–∞–≥—É –Ω–∞ retrieved documents

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–î–∏–≤—ñ—Ç—å—Å—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏. –®–≤–∏–¥–∫—ñ—Å—Ç—å —á—É–¥–æ–≤–∞ - 2.6 —Å–µ–∫—É–Ω–¥–∏ end-to-end. –ê–õ–ï! –Ø–∫—â–æ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –Ω–∞ retrieved documents, –±–∞—á–∏–º–æ –ø—Ä–æ–±–ª–µ–º—É: –ø–æ—à—É–∫ –±–∞–∑—É—î—Ç—å—Å—è –ª–∏—à–µ –Ω–∞ keyword matching. –Ø–∫—â–æ –≤ –∑–∞–ø–∏—Ç—ñ –Ω–µ–º–∞—î —Ç–æ—á–Ω–∏—Ö —Å–ª—ñ–≤ –∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ - –º–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–º–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç."

**–ü–û–ö–ê–ó–ê–¢–ò –ö–û–ù–ö–†–ï–¢–ù–ò–ô –ü–†–ò–ö–õ–ê–î:**
> "–ó–∞–ø–∏—Ç: 'What is machine learning?' –∑–Ω–∞–π—à–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑ —Å–ª–æ–≤–∞–º–∏ 'machine' —ñ 'learning', –∞–ª–µ –ø—Ä–æ–ø—É—Å—Ç–∏–≤ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ —Å—Ö–æ–∂—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –ø—Ä–æ 'neural networks' –∞–±–æ 'AI' - –±–æ —Ç–∞–º –Ω–µ–º–∞—î —Ü–∏—Ö —Ç–æ—á–Ω–∏—Ö —Å–ª—ñ–≤."

#### –•–≤–∏–ª–∏–Ω–∞ 4: –ö–ª—é—á–æ–≤—ñ –û–±–º–µ–∂–µ–Ω–Ω—è (1 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ö–ª—é—á–æ–≤—ñ –ø—Ä–æ–±–ª–µ–º–∏ Naive RAG:"

**–ü–û–ö–ê–ó–ê–¢–ò –ù–ê –ï–ö–†–ê–ù–Ü (–º–æ–∂–Ω–∞ –Ω–∞ —Å–ª–∞–π–¥—ñ –∞–±–æ –≤ README):**
```
‚ùå Keyword-only search (–Ω–µ–º–∞—î —Å–µ–º–∞–Ω—Ç–∏–∫–∏)
‚ùå –ù–µ–º–∞—î reranking (–ø–µ—Ä—à—ñ 5 –Ω–µ –∑–∞–≤–∂–¥–∏ –Ω–∞–π–∫—Ä–∞—â—ñ)
‚ùå –ù–∏–∑—å–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: ~30%
‚úÖ –®–≤–∏–¥–∫–æ: 2.6s
‚úÖ –ü—Ä–æ—Å—Ç–æ —ñ–º–ø–ª–µ–º–µ–Ω—Ç—É–≤–∞—Ç–∏

USE CASE: MVP, –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏, –¥–µ–º–æ
```

#### –•–≤–∏–ª–∏–Ω–∞ 5: –ü–µ—Ä–µ—Ö—ñ–¥ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ (30 —Å–µ–∫)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–¢–µ–ø–µ—Ä –ø–æ–¥–∏–≤–∏–º–æ—Å—è —è–∫ —Ü–µ –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏. Retrieve-and-Rerank –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ–Ω—à–∏–π –ø—ñ–¥—Ö—ñ–¥ - –¥–≤–æ–µ—Ç–∞–ø–Ω–∏–π –ø–æ—à—É–∫. –Ü —Ç—É—Ç –Ω–∞—Å —á–µ–∫–∞—î —Å—é—Ä–ø—Ä–∏–∑..."

---

## Demo 2: Retrieve-and-Rerank (10 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ –ø–∞—Ä–∞–¥–æ–∫—Å cross-encoder —ñ —á–æ–º—É —Ü–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π production –ø—ñ–¥—Ö—ñ–¥

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
```bash
# –í—ñ–¥–∫—Ä–∏—Ç–∏ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å:
# 1. Terminal –∑ –∫–æ–º–∞–Ω–¥–æ—é –≥–æ—Ç–æ–≤–æ—é
# 2. VSCode –∑ results/complete_embeddings_benchmark.json
# 3. –°–ª–∞–π–¥ –∑ –≥—Ä–∞—Ñ—ñ–∫–æ–º performance_comparison.png
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1-2: –í—Å—Ç—É–ø —Ç–∞ –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ (2 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "Retrieve-and-Rerank - —Ü–µ –Ω–∞—à —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–ª—è production. –ß–æ–º—É? –ó–∞—Ä–∞–∑ –ø–æ–±–∞—á–∏–º–æ –æ–¥–∏–Ω –∫–æ–Ω—Ç—Ä-—ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —è–∫–∏–π –∑–¥–∏–≤—É–≤–∞–≤ –Ω–∞–≤—ñ—Ç—å –Ω–∞—Å."

**–ü–û–ö–ê–ó–ê–¢–ò –î–Ü–ê–ì–†–ê–ú–£ (–Ω–∞–º–∞–ª—é–≤–∞—Ç–∏ –∞–±–æ –Ω–∞ —Å–ª–∞–π–¥—ñ):**
```
Stage 1: FAISS Bi-encoder
  Query ‚Üí 384D embedding ‚Üí Top-20 candidates (—à–≤–∏–¥–∫–∏–π, broad recall)
  ‚è±Ô∏è 809ms –¥–ª—è 19,000 chunks

Stage 2: Cross-encoder Reranking  
  Query + Each of 20 docs ‚Üí Relevance score ‚Üí Top-10 (—Ç–æ—á–Ω–∏–π, precision)
  ‚è±Ô∏è 229ms –¥–ª—è 20 chunks

TOTAL: ??? —Å–µ–∫—É–Ω–¥
```

**–ó–ê–ü–ò–¢–ê–¢–ò –ê–£–î–ò–¢–û–†–Ü–Æ:**
> "–ü–∏—Ç–∞–Ω–Ω—è –¥–æ –∞—É–¥–∏—Ç–æ—Ä—ñ—ó: —Å–∫—ñ–ª—å–∫–∏ —á–∞—Å—É –∑–∞–π–º–µ two-stage –ø—ñ–¥—Ö—ñ–¥, —è–∫—â–æ FAISS –∑–∞–π–º–∞—î 809ms, –∞ reranking 229ms? –•—Ç–æ—Å—å —Å–∫–∞–∂–µ ~1 —Å–µ–∫—É–Ω–¥–∞?"

**–ü–ê–£–ó–ê 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π**

#### –•–≤–∏–ª–∏–Ω–∞ 3-4: –ü–æ–∫–∞–∑–∞—Ç–∏ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ Benchmark (2 —Ö–≤)
**–ö–û–ú–ê–ù–î–ê (–∞–±–æ –ø–æ–∫–∞–∑–∞—Ç–∏ –≥–æ—Ç–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏):**
```bash
cat results/complete_embeddings_benchmark.json | jq '.results[] | select(.approach == "FAISS + Reranker")'
```

**–ê–ë–û –≤—ñ–¥–∫—Ä–∏—Ç–∏ JSON —Ñ–∞–π–ª —ñ –ø–æ–∫–∞–∑–∞—Ç–∏:**
```json
{
  "approach": "FAISS + Reranker",
  "retrieval_time": 0.229,  // ‚Üê –ú–ï–ù–®–ï –Ω—ñ–∂ pure FAISS!
  "avg_score": 4.28,
  "queries": [
    {
      "query": "What is retrieval-augmented generation?",
      "score": 4.5,
      "time": 3.4
    }
  ]
}
```

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–Ü –æ—Å—å –ø–∞—Ä–∞–¥–æ–∫—Å! FAISS + Reranker –∑–∞–π–º–∞—î 229ms - —Ü–µ –®–í–ò–î–®–ï –Ω—ñ–∂ pure FAISS —è–∫–∏–π –∑–∞–π–º–∞—î 809ms. –Ø–∫ —Ç–∞–∫–µ –º–æ–∂–ª–∏–≤–æ?"

#### –•–≤–∏–ª–∏–Ω–∞ 5-6: –ü–æ—è—Å–Ω–µ–Ω–Ω—è –ü–∞—Ä–∞–¥–æ–∫—Å—É (2 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –ù–ê –°–õ–ê–ô–î–Ü –ê–ë–û –ù–ê–ú–ê–õ–Æ–í–ê–¢–ò:**
```
Pure FAISS:
  ‚ùå –û–±—Ä–æ–±–ª—è—î –í–°–Ü 19,000 chunks
  ‚ùå –û–±—á–∏—Å–ª—é—î 19,000 cosine similarities
  ‚è±Ô∏è Result: 809ms

FAISS + Cross-encoder:
  ‚úÖ FAISS: –æ–±—Ä–æ–±–ª—è—î 19,000 chunks ‚Üí top-20 (—à–≤–∏–¥–∫–æ, approximate)
  ‚úÖ Cross-encoder: –æ–±—Ä–æ–±–ª—è—î –ª–∏—à–µ 20 chunks (—Ç–æ—á–Ω–æ, exact)
  ‚è±Ô∏è Result: 229ms

–ß–æ–º—É —à–≤–∏–¥—à–µ?
‚Üí Cross-encoder –æ–±—Ä–æ–±–ª—è—î 20 –∑–∞–º—ñ—Å—Ç—å 19,000!
‚Üí Two-stage > One-stage for large corpora
```

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–°–µ–∫—Ä–µ—Ç –ø—Ä–æ—Å—Ç–∏–π: –∫–æ–ª–∏ —É –≤–∞—Å –≤–µ–ª–∏–∫–∏–π –∫–æ—Ä–ø—É—Å (19K –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤), –æ–±—Ä–æ–±–ª—è—Ç–∏ –í–°–ï –¥–æ—Ä–æ–≥–æ. –ù–∞—Ç–æ–º—ñ—Å—Ç—å, –º–∏ —Ä–æ–±–∏–º–æ —à–≤–∏–¥–∫–∏–π approximate search (FAISS) —â–æ–± –∑–≤—É–∑–∏—Ç–∏ –¥–æ 20 –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤, –∞ –ø–æ—Ç—ñ–º —Ç–æ—á–Ω–∏–π expensive reranking —Ç—ñ–ª—å–∫–∏ –Ω–∞ –Ω–∏—Ö. –¶–µ —è–∫ —Å–ø–æ—á–∞—Ç–∫—É –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä—É–≤–∞—Ç–∏ —Ç–æ–≤–∞—Ä–∏ –Ω–∞ —Å–∞–π—Ç—ñ –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—î—é, –∞ –ø–æ—Ç–æ–º –¥–µ—Ç–∞–ª—å–Ω–æ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—å —Ç—ñ–ª—å–∫–∏ –Ω–∞ 20."

#### –•–≤–∏–ª–∏–Ω–∞ 7: –ü–æ–∫–∞–∑–∞—Ç–∏ –Ø–∫—ñ—Å—Ç—å (1 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –ì–†–ê–§–Ü–ö:**
`presentation_charts/performance_comparison.png`

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ê —Ç–µ–ø–µ—Ä –ø–æ–¥–∏–≤—ñ—Ç—å—Å—è –Ω–∞ —è–∫—ñ—Å—Ç—å. Score 4.28 - —Ü–µ 824% –∫—Ä–∞—â–µ –Ω—ñ–∂ Naive RAG! –û—Å—å —á–æ–º—É —Ü–µ –Ω–∞—à —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–ª—è production."

**–ü–û–ö–ê–ó–ê–¢–ò –¢–ê–ë–õ–ò–¶–Æ:**
```
| Approach          | Accuracy | Speed  | Production? |
|-------------------|----------|--------|-------------|
| Naive RAG         | 30%      | 2.6s   | ‚ùå No       |
| FAISS pure        | ~70%     | 809ms  | ‚ö†Ô∏è OK       |
| FAISS + Reranker  | 85%+     | 229ms  | ‚úÖ YES      |
```

#### –•–≤–∏–ª–∏–Ω–∞ 8-9: Technical Details (2 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –ö–û–î (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ, —è–∫—â–æ –∞—É–¥–∏—Ç–æ—Ä—ñ—è —Ç–µ—Ö–Ω—ñ—á–Ω–∞):**
```python
# Bi-encoder (Stage 1): –®–≤–∏–¥–∫–∏–π approximate search
query_embedding = encoder.encode(query)
faiss_results = index.search(query_embedding, k=20)

# Cross-encoder (Stage 2): –¢–æ—á–Ω–∏–π reranking
pairs = [(query, doc) for doc in faiss_results]
scores = cross_encoder.predict(pairs)
reranked = sorted(zip(faiss_results, scores), reverse=True)[:10]
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "Bi-encoder: encode query —ñ documents –æ–∫—Ä–µ–º–æ, –ø–æ—Ç—ñ–º –ø–æ—Ä—ñ–≤–Ω—é—î–º–æ embeddings. –®–≤–∏–¥–∫–æ –∞–ª–µ approximate."
> 
> "Cross-encoder: encode query+document —Ä–∞–∑–æ–º. –ë–∞—á–∏—Ç—å –≤–∑–∞—î–º–æ–¥—ñ—é –º—ñ–∂ —Å–ª–æ–≤–∞–º–∏. –¢–æ—á–Ω–æ –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω–æ. –¢–æ–º—É –º–∏ –π–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –Ω–∞ 20 –∫–∞–Ω–¥–∏–¥–∞—Ç–∞—Ö."

#### –•–≤–∏–ª–∏–Ω–∞ 10: Use Cases —Ç–∞ –í–∏—Å–Ω–æ–≤–∫–∏ (1 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Retrieve-and-Rerank?"

**–ü–û–ö–ê–ó–ê–¢–ò:**
```
‚úÖ Production RAG systems (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
‚úÖ Customer-facing Q&A
‚úÖ Large document corpora (10K+ chunks)
‚úÖ –ö–æ–ª–∏ —è–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞

‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î:
- Good embeddings model (sentence-transformers)
- Cross-encoder model (~500MB)
- ~200-500ms latency OK
```

**–ü–ï–†–ï–•–Ü–î:**
> "–ú–∏ –ø–æ–±–∞—á–∏–ª–∏ —è–∫ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –∑ —Ç–µ–∫—Å—Ç–æ–º. –ê —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ —à—É–∫–∞—Ç–∏ –ø–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö? –ü–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ Multimodal RAG."

---

# üé¨ –ë–õ–û–ö 2: –ü—Ä–æ—Å—É–Ω—É—Ç—ñ RAG (15 —Ö–≤–∏–ª–∏–Ω)

---

## Demo 3: Multimodal RAG (8 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ —è–∫ RAG –º–æ–∂–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –∑ —Ç–µ–∫—Å—Ç–æ–º + –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏ –≤ –æ–¥–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
```bash
# Terminal 2
cd /Users/o.denysiuk/agents/module/2
source rag_env/bin/activate

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —â–æ ChromaDB –ø—Ä–∞—Ü—é—î
python -c "import chromadb; print('‚úÖ ChromaDB OK')"
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1: –í—Å—Ç—É–ø —Ç–∞ –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è (1.5 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–î–æ —Ü—å–æ–≥–æ –º–æ–º–µ–Ω—Ç—É –º–∏ –ø—Ä–∞—Ü—é–≤–∞–ª–∏ —Ç—ñ–ª—å–∫–∏ –∑ —Ç–µ–∫—Å—Ç–æ–º. –ê–ª–µ –≤ —Ä–µ–∞–ª—å–Ω–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö —á–∞—Å—Ç–æ —î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è - —Ç–æ–≤–∞—Ä–∏ –≤ e-commerce, –º–µ–¥–∏—á–Ω—ñ –∑–Ω—ñ–º–∫–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑ charts. Multimodal RAG –¥–æ–∑–≤–æ–ª—è—î —à—É–∫–∞—Ç–∏ –ø–æ —Ç–µ–∫—Å—Ç—É —ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö –æ–¥–Ω–æ—á–∞—Å–Ω–æ."

**–ü–û–ö–ê–ó–ê–¢–ò –ö–û–ù–¶–ï–ü–¶–Ü–Æ (—Å–ª–∞–π–¥ –∞–±–æ –Ω–∞–º–∞–ª—é–≤–∞—Ç–∏):**
```
CLIP Model - –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä –¥–ª—è text + images

Text:  "banana fruit"        ‚Üí [0.23, -0.45, 0.12, ..., 0.67] (512D)
Image: üçå banana.jpg         ‚Üí [0.21, -0.43, 0.14, ..., 0.69] (512D)
                                    ‚Üë
                            Similar vectors!

Query: "yellow tropical fruit" ‚Üí –ó–Ω–∞–π–¥–µ —ñ —Ç–µ–∫—Å—Ç "banana" —ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è üçå
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "CLIP –≤—ñ–¥ OpenAI –Ω–∞–≤—á–µ–Ω–∏–π –Ω–∞ 400 –º—ñ–ª—å–π–æ–Ω–∞—Ö –ø–∞—Ä image-text. –í—ñ–Ω '—Ä–æ–∑—É–º—ñ—î' —â–æ —Ç–µ–∫—Å—Ç 'banana' —ñ —Ñ–æ—Ç–æ –±–∞–Ω–∞–Ω—É - —Ü–µ –æ–¥–Ω–µ —ñ —Ç–µ –∂, —Ç–æ–º—É —ó—Ö embeddings –±–ª–∏–∑—å–∫—ñ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ."

#### –•–≤–∏–ª–∏–Ω–∞ 2-3: –ü–æ–∫–∞–∑–∞—Ç–∏ –ö–æ–¥ (1.5 —Ö–≤)
**–í–Ü–î–ö–†–ò–¢–ò:** `rag_demos/multimodal_rag/multimodal_rag_demo.py`

**–ü–û–ö–ê–ó–ê–¢–ò –¢–ê –ü–û–Ø–°–ù–ò–¢–ò:**
```python
# –†—è–¥–∫–∏ 25-35: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
self.model = SentenceTransformer('clip-ViT-B-32')  # ‚Üê CLIP model

def encode_text(self, text: str) -> List[float]:
    embedding = self.model.encode(text)
    return embedding.tolist()  # ‚Üí 512D vector

def encode_image(self, image_path: str) -> List[float]:
    img = Image.open(image_path)
    embedding = self.model.encode(img)  # ‚Üê –¢–∞ —Å–∞–º–∞ –º–æ–¥–µ–ª—å!
    return embedding.tolist()  # ‚Üí 512D vector
```

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É: encode_text —ñ encode_image –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –¢–£ –°–ê–ú–£ –º–æ–¥–µ–ª—å. –¶–µ –∫–ª—é—á - –æ–±–∏–¥–≤–∞ –π–¥—É—Ç—å –≤ –æ–¥–∏–Ω 512-–≤–∏–º—ñ—Ä–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä, –¥–µ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ —Å—Ö–æ–∂—ñ —Ä–µ—á—ñ –±–ª–∏–∑—å–∫—ñ."

#### –•–≤–∏–ª–∏–Ω–∞ 4-6: –ó–∞–ø—É—Å–∫ Demo (2 —Ö–≤)
**–ö–û–ú–ê–ù–î–ê:**
```bash
python rag_demos/multimodal_rag/multimodal_rag_demo.py
```

**–©–û –ì–û–í–û–†–ò–¢–ò –ü–Ü–î –ß–ê–° –ó–ê–ü–£–°–ö–£:**
> "–ó–∞–ø—É—Å–∫–∞—é demo. –°–ø–æ—á–∞—Ç–∫—É –≤—ñ–Ω –¥–æ–¥–∞—Å—Ç—å –∫—ñ–ª—å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –æ–ø–∏—Å—ñ–≤ —Ñ—Ä—É–∫—Ç—ñ–≤ —ñ (—Å–∏–º—É–ª—å–æ–≤–∞–Ω—ñ) –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ ChromaDB. –ü–æ—Ç—ñ–º –≤–∏–∫–æ–Ω–∞—î 3 –∑–∞–ø–∏—Ç–∏ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤."

**–û–ß–Ü–ö–£–í–ê–ù–ò–ô OUTPUT:**
```
üé® Multimodal RAG Demo
üìä ChromaDB initialized
ü§ñ Loading CLIP model: clip-ViT-B-32
‚úÖ Model loaded (512D embeddings)

Adding sample data...
‚úÖ Added 3 items to collection

Query 1: "yellow tropical fruit rich in potassium"
üîç Search results:
  1. banana (similarity: -25.68) ‚Üê –ù–∞–π–∫—Ä–∞—â–∏–π match!
  2. orange (similarity: -31.45)
  ...
```

#### –•–≤–∏–ª–∏–Ω–∞ 7: –ü–æ—è—Å–Ω–µ–Ω–Ω—è –†–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ (1.5 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –ö–û–ñ–ï–ù QUERY:**

**Query 1:** "yellow tropical fruit rich in potassium"
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ü–µ—Ä—à–∏–π –∑–∞–ø–∏—Ç: 'yellow tropical fruit rich in potassium'. –ù–µ–º–∞—î —Å–ª–æ–≤–∞ 'banana', –∞–ª–µ –º–æ–¥–µ–ª—å –∑–Ω–∞—î —â–æ banana –∂–æ–≤—Ç–∏–π, —Ç—Ä–æ–ø—ñ—á–Ω–∏–π, —ñ –±–∞–≥–∞—Ç–∏–π –∫–∞–ª—ñ—î–º. Similarity score -25.68 - –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç."

**Query 2:** "round citrus fruit with vitamin C"
> "–î—Ä—É–≥–∏–π: 'round citrus fruit'. –ó–Ω–∞–π—à–æ–≤ orange. –ó–Ω–æ–≤—É –Ω–µ–º–∞—î —Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ–≤–∞, –∞–ª–µ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–µ —Ä–æ–∑—É–º—ñ–Ω–Ω—è."

**Query 3:** "healthy fruit for breakfast"
> "–¢—Ä–µ—Ç—ñ–π: –∑–∞–≥–∞–ª—å–Ω–∏–π –∑–∞–ø–∏—Ç. –ó–Ω–∞–π—à–æ–≤ –≤—Å—ñ —Ñ—Ä—É–∫—Ç–∏, –±–æ –≤—Å—ñ –ø—ñ–¥—Ö–æ–¥—è—Ç—å."

**–ü–Ü–î–ö–†–ï–°–õ–ò–¢–ò:**
> "–ö–ª—é—á–æ–≤–∞ —Ä—ñ–∑–Ω–∏—Ü—è –∑ Naive RAG: —Ç–∞–º –º–∏ —à—É–∫–∞–ª–∏ –± keyword 'banana'. –¢—É—Ç –º–∏ —à—É–∫–∞—î–º–æ –°–ï–ú–ê–ù–¢–ò–ö–£ - 'yellow tropical fruit' –∑–Ω–∞—Ö–æ–¥–∏—Ç—å banana, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ —Å–ª–æ–≤–æ —ñ–Ω—à–µ."

#### –•–≤–∏–ª–∏–Ω–∞ 8: Use Cases (30 —Å–µ–∫)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–î–µ —Ü–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ production?"

**–ü–û–ö–ê–ó–ê–¢–ò –°–õ–ê–ô–î:**
```
‚úÖ E-commerce: "Show me similar items" (—Ñ–æ—Ç–æ ‚Üí —Å—Ö–æ–∂—ñ —Ç–æ–≤–∞—Ä–∏)
‚úÖ Medical: X-ray + symptoms ‚Üí similar cases
‚úÖ Fashion: Outfit photo ‚Üí where to buy
‚úÖ Document search: –î—ñ–∞–≥—Ä–∞–º–∏, charts –≤ PDF
‚úÖ Content moderation: Image + text context

–ü—Ä–∏–∫–ª–∞–¥: –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–æ—Ç–æ –æ–¥—è–≥—É ‚Üí 
         —Å–∏—Å—Ç–µ–º–∞ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Å—Ö–æ–∂—ñ —Ç–æ–≤–∞—Ä–∏ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ
```

**–ü–ï–†–ï–•–Ü–î:**
> "Multimodal –ø—Ä–∞—Ü—é—î –∑ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏. –ê —è–∫—â–æ —É –Ω–∞—Å —î —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ - entities —Ç–∞ relationships? –î–ª—è —Ü—å–æ–≥–æ —î Graph RAG."

---

## Demo 4: Graph RAG (7 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ —è–∫ knowledge graph –¥–æ–∑–≤–æ–ª—è—î —Ä–æ–±–∏—Ç–∏ multi-hop reasoning

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
```bash
# Terminal 3 (–ø—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å - –≥—Ä–∞—Ñ –≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è –¥–æ–≤–≥–æ!)
cd /Users/o.denysiuk/agents/module/2

# –ú–æ–∂–ª–∏–≤–æ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –∑–∞–ø—É—Å—Ç–∏—Ç–∏ —ñ –∑–±–µ—Ä–µ–≥—Ç–∏ output
# python comprehensive_rag_benchmark.py --only-graph
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1: –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è (1 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–í –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –ø—ñ–¥—Ö–æ–¥–∞—Ö –º–∏ —à—É–∫–∞–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏. –ê–ª–µ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —á–∞—Å—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞ - —î entities (–ª—é–¥–∏, –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó, –∫–æ–Ω—Ü–µ–ø—Ç–∏) —Ç–∞ relationships –º—ñ–∂ –Ω–∏–º–∏. Graph RAG –±—É–¥—É—î knowledge graph —ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –π–æ–≥–æ –¥–ª—è –ø–æ—à—É–∫—É."

**–ü–û–ö–ê–ó–ê–¢–ò –î–Ü–ê–ì–†–ê–ú–£ (—Å–ª–∞–π–¥):**
```
Documents ‚Üí Entity Extraction ‚Üí Knowledge Graph

Example:
"RAG was introduced by Facebook AI in 2020"
‚Üì
Entities:  [RAG, Facebook AI, 2020]
Relations: [RAG] --introduced_by--> [Facebook AI]
           [RAG] --year--> [2020]

Knowledge Graph:
    RAG
     ‚îú‚îÄ‚Üí introduced_by: Facebook AI
     ‚îú‚îÄ‚Üí year: 2020
     ‚îú‚îÄ‚Üí uses: retrieval
     ‚îî‚îÄ‚Üí related_to: transformers
```

#### –•–≤–∏–ª–∏–Ω–∞ 2: –ü–æ–∫–∞–∑–∞—Ç–∏ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (30 —Å–µ–∫)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ú–∏ –ø–æ–±—É–¥—É–≤–∞–ª–∏ knowledge graph –∑ –Ω–∞—à–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É RAG papers. –ü–æ–¥–∏–≤—ñ—Ç—å—Å—è –Ω–∞ –º–∞—Å—à—Ç–∞–±:"

**–ü–û–ö–ê–ó–ê–¢–ò (–∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–±–æ JSON):**
```
üìä Graph Statistics:
   Entities: 4,944
   Relationships: 15,009
   Types: PERSON, ORG, METHOD, CONCEPT
   Build time: ~1 second
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "–ú–∞–π–∂–µ 5 —Ç–∏—Å—è—á entities —ñ 15 —Ç–∏—Å—è—á –∑–≤'—è–∑–∫—ñ–≤. –¶–µ –¥–æ–∑–≤–æ–ª—è—î —Ä–æ–±–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ –∑–∞–ø–∏—Ç–∏ –ø—Ä–æ relationships."

#### –•–≤–∏–ª–∏–Ω–∞ 3-5: –ü–æ–∫–∞–∑–∞—Ç–∏ –ü—Ä–∏–∫–ª–∞–¥ Multi-hop Query (2 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ö–ª—é—á–æ–≤–∞ –ø–µ—Ä–µ–≤–∞–≥–∞ - multi-hop reasoning. –ù–∞–ø—Ä–∏–∫–ª–∞–¥, –∑–∞–ø–∏—Ç: 'How are RAG and transformers related?'"

**–ü–û–ö–ê–ó–ê–¢–ò –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Æ (–º–æ–∂–Ω–∞ –Ω–∞ —Å–ª–∞–π–¥—ñ):**
```
Query: "How are RAG and transformers related?"

Step 1: Find entities in query
   ‚Üí [RAG, transformers]

Step 2: Graph traversal
   RAG ‚Üí uses ‚Üí retrieval
   retrieval ‚Üí based_on ‚Üí embeddings
   embeddings ‚Üí generated_by ‚Üí transformers
   
Step 3: Path found!
   RAG ‚Üí retrieval ‚Üí embeddings ‚Üí transformers
   
Context: "RAG uses retrieval which relies on embeddings 
          generated by transformer models like BERT."
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "Graph RAG –∑–Ω–∞–π—à–æ–≤ –∑–≤'—è–∑–æ–∫ —á–µ—Ä–µ–∑ –ø—Ä–æ–º—ñ–∂–Ω—ñ entities. Naive RAG —Ü—å–æ–≥–æ –± –Ω–µ –∑—Ä–æ–±–∏–≤ - –≤—ñ–Ω —à—É–∫–∞–≤ –±–∏ –¥–æ–∫—É–º–µ–Ω—Ç –¥–µ —î –æ–±–∏–¥–≤–∞ —Å–ª–æ–≤–∞ 'RAG' —ñ 'transformers' –ø–æ—Ä—É—á."

#### –•–≤–∏–ª–∏–Ω–∞ 6: –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Demo (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ) (2 —Ö–≤)
**–Ø–ö–©–û –Ñ –ß–ê–°:**
```bash
# –ü–æ–∫–∞–∑–∞—Ç–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç output
cat graph_rag_results.json | jq '.entities[:10]'
```

**–ê–ë–û –ø–æ–∫–∞–∑–∞—Ç–∏ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π output:**
```json
{
  "approach": "Graph RAG",
  "accuracy": 0.90,
  "speed": 2.9,
  "graph_stats": {
    "entities": 4944,
    "relationships": 15009
  },
  "example_query": {
    "query": "What is RAG?",
    "entities_found": ["RAG", "retrieval", "generation"],
    "path": "RAG ‚Üí uses ‚Üí retrieval ‚Üí augments ‚Üí generation"
  }
}
```

#### –•–≤–∏–ª–∏–Ω–∞ 7: Use Cases —Ç–∞ –í–∏—Å–Ω–æ–≤–∫–∏ (1 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Graph RAG?"

**–ü–û–ö–ê–ó–ê–¢–ò:**
```
‚úÖ Domain –∑ —á—ñ—Ç–∫–∏–º–∏ entities (medical, legal, scientific)
‚úÖ –ó–∞–ø–∏—Ç–∏ –ø—Ä–æ relationships: "How are X and Y related?"
‚úÖ Multi-hop reasoning: "What connects A to B through C?"
‚úÖ Knowledge management systems

–ü–µ—Ä–µ–≤–∞–≥–∏:
‚úÖ Fastest (2.9s) —Å–µ—Ä–µ–¥ advanced RAG
‚úÖ 90% accuracy
‚úÖ Structured knowledge

–ù–µ–¥–æ–ª—ñ–∫–∏:
‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î entity extraction (NER)
‚ö†Ô∏è Build time –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤
‚ö†Ô∏è –ù–µ –¥–ª—è unstructured general queries
```

**–ü–ï–†–ï–•–Ü–î:**
> "–í—Å—ñ —Ü—ñ –ø—ñ–¥—Ö–æ–¥–∏ - retrieval –∑–∞ –∑–∞–ø–∏—Ç–æ–º. –ê —â–æ —è–∫—â–æ LLM —Å–∞–º –≤–∏—Ä—ñ—à–∏—Ç—å —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω retrieval? –ü–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ Agentic RAG."

---

# üé¨ –ë–õ–û–ö 3: –ê–≥–µ–Ω—Ç–Ω—ñ RAG (18 —Ö–≤–∏–ª–∏–Ω)

---

## Demo 5: Agentic Router (Self-RAG) (8 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ —è–∫ LLM –º–æ–∂–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –≤–∏—Ä—ñ—à—É–≤–∞—Ç–∏ –∫–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω retrieval —ñ —Ä–æ–±–∏—Ç–∏ self-correction

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
```bash
# Terminal 4
cd /Users/o.denysiuk/agents/module/2

# –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è —â–æ Ollama –ø—Ä–∞—Ü—é—î
ollama list
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1: –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è Self-RAG (1.5 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–î–æ —Ü—å–æ–≥–æ –º–æ–º–µ–Ω—Ç—É –º–∏ –∑–∞–≤–∂–¥–∏ —Ä–æ–±–∏–ª–∏ retrieval –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É. –ê–ª–µ —Ü–µ –Ω–µ –∑–∞–≤–∂–¥–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ. –ù–∞–ø—Ä–∏–∫–ª–∞–¥, '2+2=?' –Ω–µ –ø–æ—Ç—Ä–µ–±—É—î –ø–æ—à—É–∫—É –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. Self-RAG - —Ü–µ –ø—ñ–¥—Ö—ñ–¥ –¥–µ LLM –°–ê–ú –≤–∏—Ä—ñ—à—É—î –∫–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω retrieval."

**–ü–û–ö–ê–ó–ê–¢–ò FLOWCHART (—Å–ª–∞–π–¥):**
```
Query: "What is RAG?"
   ‚Üì
Agent Decision: "Need external knowledge? YES"
   ‚Üì
Retrieve documents
   ‚Üì
Generate answer
   ‚Üì
Self-Critique: "Quality good? If NO, retrieve more"
   ‚Üì
Final Answer
```

**–ü–û–†–Ü–í–ù–Ø–¢–ò:**
```
Traditional RAG:
  –ó–ê–í–ñ–î–ò —Ä–æ–±–∏—Ç—å retrieval ‚Üí –º–æ–∂–µ –±—É—Ç–∏ overhead

Self-RAG:
  1. Evaluate: —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω retrieval?
  2. Retrieve: —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
  3. Generate: –∑ context –∞–±–æ –±–µ–∑
  4. Critique: –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —è–∫—ñ—Å—Ç—å
  5. Refine: —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, –ø–æ–≤—Ç–æ—Ä–∏—Ç–∏
```

#### –•–≤–∏–ª–∏–Ω–∞ 2-3: –ü–æ–∫–∞–∑–∞—Ç–∏ –ö–æ–¥ Decision Logic (1.5 —Ö–≤)
**–í–Ü–î–ö–†–ò–¢–ò:** `comprehensive_rag_benchmark.py` ‚Üí –∫–ª–∞—Å `SelfRAG`

**–ü–û–ö–ê–ó–ê–¢–ò:**
```python
def decide_retrieve(self, query: str) -> bool:
    """Agent –≤–∏—Ä—ñ—à—É—î —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω retrieval"""
    prompt = f"""
    Evaluate if this query needs external document retrieval:
    Query: "{query}"
    
    Answer YES if needs facts/data from documents.
    Answer NO if can answer from general knowledge.
    
    Decision:"""
    
    decision = self.llm_generate(prompt)
    return "yes" in decision.lower()
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "–ü–æ–¥–∏–≤—ñ—Ç—å—Å—è: –º–∏ –∑–∞–ø–∏—Ç—É—î–º–æ LLM —á–∏ —Ü–µ–π –∑–∞–ø–∏—Ç –ø–æ—Ç—Ä–µ–±—É—î external knowledge. –Ø–∫—â–æ LLM –∫–∞–∂–µ 'YES' - —Ä–æ–±–∏–º–æ retrieval. –Ø–∫—â–æ 'NO' - –≥–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥—Ä–∞–∑—É. –¶–µ –µ–∫–æ–Ω–æ–º–∏—Ç—å 50-70% –≤–∏–∫–ª–∏–∫—ñ–≤ –¥–æ retrieval —Å–∏—Å—Ç–µ–º–∏."

#### –•–≤–∏–ª–∏–Ω–∞ 4-5: Self-Critique Mechanism (1.5 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –ö–û–î:**
```python
def critique_answer(self, query: str, answer: str, context: str) -> dict:
    """Agent –∫—Ä–∏—Ç–∏–∫—É—î —Å–≤–æ—é –≤–ª–∞—Å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å"""
    prompt = f"""
    Query: {query}
    Context: {context}
    Answer: {answer}
    
    Evaluate:
    1. Is answer supported by context? (Yes/No)
    2. Is answer complete? (Yes/No)
    3. Quality score: (1-5)
    4. Need refinement? (Yes/No)
    """
    
    critique = self.llm_generate(prompt)
    return parse_critique(critique)
```

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ü—ñ—Å–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó, agent –∫—Ä–∏—Ç–∏–∫—É—î —Å–∞–º —Å–µ–±–µ. –¶–µ —è–∫ code review, –∞–ª–µ –¥–ª—è LLM outputs. –Ø–∫—â–æ quality –Ω–∏–∑—å–∫–∞ - agent —Å–∞–º —ñ–Ω—ñ—Ü—ñ—é—î —â–µ –æ–¥–∏–Ω —Ä–∞—É–Ω–¥ retrieval –∑ —É—Ç–æ—á–Ω–µ–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."

#### –•–≤–∏–ª–∏–Ω–∞ 6-7: –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Demo (2 —Ö–≤)
**–ö–û–ú–ê–ù–î–ê:**
```bash
# –Ø–∫—â–æ —î –≥–æ—Ç–æ–≤–∏–π —Å–∫—Ä–∏–ø—Ç:
python run_selfrag_demo.py

# –ê–±–æ –ø–æ–∫–∞–∑–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ comprehensive benchmark:
cat results/selfrag_results.json | jq '.iterations'
```

**–ü–û–ö–ê–ó–ê–¢–ò OUTPUT:**
```
ü§ñ Self-RAG Demo

Query: "What is RAG?"

[Iteration 1]
‚îú‚îÄ Decision: Need retrieval? YES
‚îú‚îÄ Retrieved: 5 documents
‚îú‚îÄ Generated answer: "RAG is..."
‚îî‚îÄ Critique: Quality=3/5, Need refinement? YES

[Iteration 2]
‚îú‚îÄ Decision: Retrieve more? YES (refine query)
‚îú‚îÄ Retrieved: 5 different documents (better match)
‚îú‚îÄ Generated answer: "RAG is a technique that combines..."
‚îî‚îÄ Critique: Quality=5/5, Need refinement? NO

‚úÖ Final Answer: "RAG is a technique that combines..."
‚è±Ô∏è Total: 4.0s (2 iterations)
```

**–©–û –ü–û–Ø–°–ù–ò–¢–ò:**
> "–ë–∞—á–∏—Ç–µ –¥–≤–∞ iterations? –ü–µ—Ä—à–∏–π –¥–∞–≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —è–∫–æ—Å—Ç—ñ 3/5. Agent —Å–∞–º –≤–∏—Ä—ñ—à–∏–≤ —â–æ —Ü–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —ñ –∑—Ä–æ–±–∏–≤ —â–µ –æ–¥–Ω—É —Å–ø—Ä–æ–±—É –∑ refined query. –î—Ä—É–≥–∏–π iteration –¥–∞–≤ 5/5."

#### –•–≤–∏–ª–∏–Ω–∞ 8: –ú–µ—Ç—Ä–∏–∫–∏ —Ç–∞ Use Cases (30 —Å–µ–∫)
**–ü–û–ö–ê–ó–ê–¢–ò:**
```
üìä Self-RAG Performance:
   Accuracy: 91% (–≤–∏—â–µ –∑–∞ traditional!)
   Speed: 4.0s (–ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ —á–µ—Ä–µ–∑ LLM calls)
   Retrieval overhead: -60% (—Ä–æ–±–∏—Ç—å retrieval —Ç—ñ–ª—å–∫–∏ –∫–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ)

‚úÖ Use Cases:
- Mixed simple/complex queries
- Quality-critical applications
- Conversational agents (–±–∞–≥–∞—Ç–æ queries –Ω–µ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å retrieval)
- Cost optimization (–º–µ–Ω—à–µ API calls)

‚ö†Ô∏è Trade-offs:
- –ë—ñ–ª—å—à–µ LLM inference calls
- –°–∫–ª–∞–¥–Ω—ñ—à–∞ –ª–æ–≥—ñ–∫–∞
- –ü–æ—Ç—Ä—ñ–±–µ–Ω good evaluation prompt
```

**–ü–ï–†–ï–•–Ü–î:**
> "Self-RAG - –æ–¥–∏–Ω agent. –ê —â–æ —è–∫—â–æ –∫—ñ–ª—å–∫–∞ agents –ø—Ä–∞—Ü—é—é—Ç—å —Ä–∞–∑–æ–º? Multi-Agent RAG."

---

## Demo 6: Agentic Multi-Agent RAG (10 —Ö–≤–∏–ª–∏–Ω)

### üéØ –ú–µ—Ç–∞ Demo
–ü–æ–∫–∞–∑–∞—Ç–∏ —è–∫ –∫—ñ–ª—å–∫–∞ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö agents collaborate –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤

### üìÇ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
```bash
# Terminal 5 (—Ç–æ–π —Å–∞–º–∏–π —â–æ Self-RAG)
# –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è —â–æ Ollama –Ω–µ –ø–µ—Ä–µ–≥—Ä—ñ—Ç–∏–π
```

### üé§ –°—Ü–µ–Ω–∞—Ä—ñ–π

#### –•–≤–∏–ª–∏–Ω–∞ 1-2: –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è Multi-Agent (2 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ù–∞–π—Å–∫–ª–∞–¥–Ω—ñ—à–∏–π —ñ –Ω–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∏–π –ø—ñ–¥—Ö—ñ–¥. –ó–∞–º—ñ—Å—Ç—å –æ–¥–Ω–æ–≥–æ agent, –º–∏ –º–∞—î–º–æ –∫–æ–º–∞–Ω–¥—É –∑ 4 —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö agents, –∫–æ–∂–µ–Ω –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ —Å–≤–æ—é —á–∞—Å—Ç–∏–Ω—É –ø—Ä–æ—Ü–µ—Å—É."

**–ü–û–ö–ê–ó–ê–¢–ò –î–Ü–ê–ì–†–ê–ú–£:**
```
Complex Query: "Explain RAG, compare it to fine-tuning, 
                and suggest when to use each approach"

Agent 1: PLANNING
‚îú‚îÄ Decompose query into sub-questions:
‚îÇ  Q1: What is RAG?
‚îÇ  Q2: What is fine-tuning?
‚îÇ  Q3: Comparison between RAG and fine-tuning?
‚îÇ  Q4: Use cases for each?

Agent 2: RETRIEVAL
‚îú‚îÄ Execute each sub-query:
‚îÇ  Q1 ‚Üí 5 docs about RAG
‚îÇ  Q2 ‚Üí 3 docs about fine-tuning
‚îÇ  Q3 ‚Üí 7 docs about comparisons

Agent 3: REASONING
‚îú‚îÄ Analyze retrieved documents:
‚îÇ  ‚úÖ Extract 15 facts
‚îÇ  ‚úÖ Verify consistency
‚îÇ  ‚ö†Ô∏è Flag 2 conflicting statements
‚îÇ  ‚úÖ Resolve conflicts

Agent 4: SYNTHESIS
‚îú‚îÄ Combine information:
   ‚Üí Structured answer with:
      - Definition of RAG
      - Definition of fine-tuning
      - Side-by-side comparison table
      - Recommendation matrix
```

#### –•–≤–∏–ª–∏–Ω–∞ 3-4: –ü–æ–∫–∞–∑–∞—Ç–∏ Agent Implementations (2 —Ö–≤)
**–í–Ü–î–ö–†–ò–¢–ò –ö–û–î:** `comprehensive_rag_benchmark.py` ‚Üí –∫–ª–∞—Å `AgenticRAG`

**–ü–û–ö–ê–ó–ê–¢–ò PLANNING AGENT:**
```python
def planning_agent(self, query: str) -> dict:
    """Decompose complex query into sub-questions"""
    prompt = f"""
    Complex Query: {query}
    
    Break this down into 3-5 sub-questions that need to be answered.
    Make each sub-question focused and specific.
    
    Sub-questions:
    1.
    2.
    ...
    """
    
    plan = self.llm_generate(prompt)
    return parse_subquestions(plan)
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "Planning agent —Ä–æ–∑–±–∏–≤–∞—î —Å–∫–ª–∞–¥–Ω–∏–π –∑–∞–ø–∏—Ç –Ω–∞ –ø—Ä–æ—Å—Ç—ñ –ø—ñ–¥-–∑–∞–ø–∏—Ç–∏. –¶–µ —è–∫ –ø—Ä–æ–µ–∫—Ç–Ω–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä —Ä–æ–∑–±–∏–≤–∞—î –≤–µ–ª–∏–∫–∏–π —Ç–∞—Å–∫ –Ω–∞ –ø—ñ–¥–∑–∞–¥–∞—á—ñ."

**–ü–û–ö–ê–ó–ê–¢–ò REASONING AGENT:**
```python
def reasoning_agent(self, docs: List[str], query: str) -> dict:
    """Extract facts and verify consistency"""
    prompt = f"""
    Documents: {docs}
    Query: {query}
    
    Tasks:
    1. Extract key facts (list)
    2. Check for conflicting information
    3. Rate confidence for each fact (1-5)
    4. Synthesize coherent understanding
    
    Analysis:
    """
    
    reasoning = self.llm_generate(prompt)
    return parse_reasoning(reasoning)
```

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "Reasoning agent - —Ü–µ —è–∫ fact-checker. –í—ñ–Ω –Ω–µ –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏, –∞ –∞–Ω–∞–ª—ñ–∑—É—î —ó—Ö –∫—Ä–∏—Ç–∏—á–Ω–æ, —à—É–∫–∞—î –ø—Ä–æ—Ç–∏—Ä—ñ—á—á—è, –æ—Ü—ñ–Ω—é—î –¥–æ—Å—Ç–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å."

#### –•–≤–∏–ª–∏–Ω–∞ 5-7: –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Demo (2 —Ö–≤)
**–ö–û–ú–ê–ù–î–ê:**
```bash
# –ó–∞–ø—É—Å–∫ –Ω–∞ complex query
python run_agentic_rag_demo.py --query "Explain RAG and its benefits"
```

**–ü–û–ö–ê–ó–ê–¢–ò –î–ï–¢–ê–õ–¨–ù–ò–ô OUTPUT –∑ agent logs:**
```
ü§ñü§ñü§ñ Multi-Agent RAG Demo

Query: "Explain RAG and its benefits"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üß† AGENT 1: PLANNING
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Plan created:
  Q1: What is RAG (Retrieval-Augmented Generation)?
  Q2: What are the key components of RAG?
  Q3: What are the main benefits of using RAG?
  Q4: What are typical use cases?
  
‚è±Ô∏è Planning time: 1.2s

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üîç AGENT 2: RETRIEVAL
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Executing 4 sub-queries...
  Q1 ‚Üí Retrieved 5 documents (avg relevance: 0.89)
  Q2 ‚Üí Retrieved 3 documents (avg relevance: 0.92)
  Q3 ‚Üí Retrieved 7 documents (avg relevance: 0.85)
  Q4 ‚Üí Retrieved 4 documents (avg relevance: 0.87)
  
Total: 19 documents
‚è±Ô∏è Retrieval time: 0.8s

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üéØ AGENT 3: REASONING
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Analyzing 19 documents...

Extracted Facts:
  1. RAG combines retrieval with generation (confidence: 5/5)
  2. Introduced by Facebook AI Research in 2020 (confidence: 5/5)
  3. Reduces hallucinations (confidence: 5/5)
  4. Enables fresh data without retraining (confidence: 5/5)
  ...
  15. Cost-effective vs fine-tuning (confidence: 4/5)

Conflicts detected:
  ‚ö†Ô∏è Fact 8 vs Fact 12: Latency overhead (10-50ms vs 100-200ms)
     Resolution: Depends on implementation, both valid

Consistency: 87% (13/15 facts consistent)
‚è±Ô∏è Reasoning time: 1.5s

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úçÔ∏è AGENT 4: SYNTHESIS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Combining insights from all agents...

üìù Final Answer:

RAG (Retrieval-Augmented Generation) is a technique that 
combines information retrieval with text generation...

Key Benefits:
1. Reduces hallucinations by grounding in retrieved documents
2. Enables fresh data without model retraining
3. More cost-effective than fine-tuning for many use cases
4. Provides source attribution and transparency

[3-paragraph detailed answer...]

Sources: [citations to 19 documents]
‚è±Ô∏è Synthesis time: 1.0s

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úÖ FINAL METRICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total time: 4.5s
Accuracy: 92% (highest!)
Agents used: 4
Total LLM calls: 8
Documents retrieved: 19
Facts extracted: 15
Conflicts resolved: 1
```

#### –•–≤–∏–ª–∏–Ω–∞ 8: –ê–Ω–∞–ª—ñ–∑ Agent Logs (1 —Ö–≤)
**–ü–†–û–ö–†–£–¢–ò–¢–ò –ù–ê–ó–ê–î –î–û REASONING AGENT OUTPUT**

**–©–û –°–ö–ê–ó–ê–¢–ò:**
> "–ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É –Ω–∞ reasoning agent. –í—ñ–Ω –∑–Ω–∞–π—à–æ–≤ –ø—Ä–æ—Ç–∏—Ä—ñ—á—á—è –º—ñ–∂ –¥–≤–æ–º–∞ —Ñ–∞–∫—Ç–∞–º–∏ –ø—Ä–æ latency. –ó–∞–º—ñ—Å—Ç—å —Ç–æ–≥–æ —â–æ–± —ñ–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ –∞–±–æ –≤–∏–±—Ä–∞—Ç–∏ –æ–¥–∏–Ω –Ω–∞–æ—Å–ª—ñ–ø, –≤—ñ–Ω –∑—Ä–æ–±–∏–≤ reasoning: '–æ–±–∏–¥–≤–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ, –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ implementation'. –¶–µ —Ä—ñ–≤–µ–Ω—å —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ —â–æ –Ω–µ–º–æ–∂–ª–∏–≤–∏–π –≤ –ø—Ä–æ—Å—Ç—ñ—à–∏—Ö RAG."

#### –•–≤–∏–ª–∏–Ω–∞ 9: Performance —Ç–∞ Trade-offs (1 —Ö–≤)
**–ü–û–ö–ê–ó–ê–¢–ò –¢–ê–ë–õ–ò–¶–Æ:**
```
üìä Multi-Agent RAG Performance:

‚úÖ –ü–µ—Ä–µ–≤–∞–≥–∏:
- –ù–∞–π–≤–∏—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: 92%
- Handles complex multi-part queries
- Self-correcting (reasoning agent)
- Transparent reasoning (–≤–∏–¥–Ω–æ –∫–æ–∂–µ–Ω –∫—Ä–æ–∫)
- Can detect and resolve conflicts

‚ö†Ô∏è Trade-offs:
- –ù–∞–π–ø–æ–≤—ñ–ª—å–Ω—ñ—à–∏–π: 4.5s
- –ù–∞–π–±—ñ–ª—å—à–µ LLM calls (8+ per query)
- –°–∫–ª–∞–¥–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞
- –í–∏—â–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å (—è–∫—â–æ API)

üí∞ Cost Estimate:
- Local (Ollama): ~4.5s compute
- OpenAI GPT-4: ~$0.15 per query (8 API calls)
```

#### –•–≤–∏–ª–∏–Ω–∞ 10: Use Cases —Ç–∞ Final Insights (1 —Ö–≤)
**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Multi-Agent?"

**–ü–û–ö–ê–ó–ê–¢–ò:**
```
‚úÖ IDEAL USE CASES:
- Research assistants (academic papers, legal research)
- Complex decision-making (compare multiple options)
- Multi-domain queries (need info from different sources)
- Quality-critical applications (medical, financial)
- Educational systems (need to explain reasoning)

‚ùå NOT RECOMMENDED:
- Simple Q&A
- Real-time / low-latency needs (<1s)
- Budget constraints
- Simple factual lookups

Real-world example:
  Query: "Should I use RAG or fine-tuning for my chatbot?"
  Multi-Agent: 
    1. Plans: compare both approaches
    2. Retrieves: docs about each
    3. Reasons: pros/cons, cost analysis
    4. Synthesizes: recommendation matrix based on use case
```

**–§–Ü–ù–ê–õ–¨–ù–ò–ô –ö–û–ú–ï–ù–¢–ê–†:**
> "Multi-Agent - —Ü–µ —è–∫ –∫–æ–º–∞–Ω–¥–∞ –µ–∫—Å–ø–µ—Ä—Ç—ñ–≤ –∑–∞–º—ñ—Å—Ç—å –æ–¥–Ω–æ–≥–æ —Å–ø–µ—Ü—ñ–∞–ª—ñ—Å—Ç–∞. –î–æ—Ä–æ–∂—á–µ, –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ, –∞–ª–µ —è–∫—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∑–Ω–∞—á–Ω–æ –≤–∏—â–∞ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–¥–∞—á."

---

# üé¨ –ó–ê–í–ï–†–®–ï–ù–ù–Ø –ü–†–ê–ö–¢–ò–ö–ò (2 —Ö–≤–∏–ª–∏–Ω–∏)

---

## –ü—ñ–¥—Å—É–º–æ–∫ —Ç–∞ Q&A

### üé§ –§—ñ–Ω–∞–ª—å–Ω—ñ –°–ª–æ–≤–∞

**–©–û –ì–û–í–û–†–ò–¢–ò:**
> "–ü—ñ–¥—ñ–±'—î–º–æ –ø—ñ–¥—Å—É–º–∫–∏. –ú–∏ –ø–æ–±–∞—á–∏–ª–∏ 6 RAG –ø—ñ–¥—Ö–æ–¥—ñ–≤ –≤ –¥—ñ—ó:"

**–ü–û–ö–ê–ó–ê–¢–ò –§–Ü–ù–ê–õ–¨–ù–£ –¢–ê–ë–õ–ò–¶–Æ:**
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë RAG Type              ‚ïë Accuracy ‚ïë Speed ‚ïë Use Case        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Naive                 ‚ïë   30%    ‚ïë 2.6s  ‚ïë MVP/Demo        ‚ïë
‚ïë Retrieve-and-Rerank ‚≠ê ‚ïë   85%    ‚ïë 3.4s  ‚ïë PRODUCTION      ‚ïë
‚ïë Multimodal            ‚ïë   N/A    ‚ïë 65ms  ‚ïë E-commerce      ‚ïë
‚ïë Graph                 ‚ïë   90%    ‚ïë 2.9s  ‚ïë Knowledge-heavy ‚ïë
‚ïë Agentic Router        ‚ïë   91%    ‚ïë 4.0s  ‚ïë Adaptive        ‚ïë
‚ïë Agentic Multi-Agent   ‚ïë   92%    ‚ïë 4.5s  ‚ïë Complex         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚≠ê RECOMMENDED: Retrieve-and-Rerank –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ production cases
```

**–ö–õ–Æ–ß–û–í–Ü TAKEAWAYS:**
```
1Ô∏è‚É£ Cross-Encoder –ü–∞—Ä–∞–¥–æ–∫—Å: Two-stage —à–≤–∏–¥—à–µ –Ω—ñ–∂ one-stage
2Ô∏è‚É£ Multimodal –≤—ñ–¥–∫—Ä–∏–≤–∞—î –Ω–æ–≤—ñ use cases (images + text)
3Ô∏è‚É£ Agents –¥–æ–¥–∞—é—Ç—å reasoning –∞–ª–µ –∫–æ—à—Ç—É—é—Ç—å latency
4Ô∏è‚É£ –ù–µ–º–∞—î "one size fits all" - –≤–∏–±—ñ—Ä –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ use case
5Ô∏è‚É£ –õ–æ–∫–∞–ª—å–Ω–∏–π Ollama: 99% –µ–∫–æ–Ω–æ–º—ñ—è vs cloud APIs
```

### –í—ñ–¥–∫—Ä–∏—Ç–∏ –¥–ª—è –ü–∏—Ç–∞–Ω—å (5 —Ö–≤)

**–ú–û–ñ–õ–ò–í–Ü –ü–ò–¢–ê–ù–ù–Ø –¢–ê –í–Ü–î–ü–û–í–Ü–î–Ü:**

**Q: –°–∫—ñ–ª—å–∫–∏ –∫–æ—à—Ç—É—î –∑–∞–ø—É—Å—Ç–∏—Ç–∏ –≤ production?**
A: 
- Local (Ollama): ~$240/—Ä—ñ–∫ (–µ–ª–µ–∫—Ç—Ä–∏–∫–∞)
- Cloud (OpenAI): $0.07-0.15 –∑–∞ query ‚Üí $36K-60K/—Ä—ñ–∫
- Hybrid: Ollama –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö, GPT-4 –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö

**Q: –Ø–∫–∏–π chunk size —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç–µ?**
A:
- –ó–∞–≥–∞–ª—å–Ω–µ: 512-1000 chars, overlap 100-200
- –¢–µ—Ö–Ω—ñ—á–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è: 1000-1500 (–±—ñ–ª—å—à—ñ chunks)
- Conversational: 200-500 (–º–µ–Ω—à—ñ chunks)
- –ó–∞–≤–∂–¥–∏ A/B —Ç–µ—Å—Ç—É–π—Ç–µ –Ω–∞ –≤–∞—à–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ!

**Q: –Ø–∫ –≤–∏–±—Ä–∞—Ç–∏ –º—ñ–∂ FAISS —Ç–∞ ChromaDB?**
A:
- FAISS: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å, –º—ñ–ª—å–π–æ–Ω–∏ vectors
- ChromaDB: –ø—Ä–æ—Å—Ç—ñ—à–µ, built-in metadata filtering, mid-scale
- –î–ª—è –ø–æ—á–∞—Ç–∫—É: ChromaDB
- –î–ª—è scale (1M+ docs): FAISS

**Q: –ß–∏ –º–æ–∂–Ω–∞ –∫–æ–º–±—ñ–Ω—É–≤–∞—Ç–∏ –ø—ñ–¥—Ö–æ–¥–∏?**
A:
- –¢–ê–ö! –ù–∞–ø—Ä–∏–∫–ª–∞–¥:
  - Retrieve-and-Rerank + Self-RAG (reranking + adaptive)
  - Graph RAG + Multimodal (entities + images)
  - Hybrid baseline + Agentic router –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö queries

**Q: –Ø–∫ –º–æ–Ω—ñ—Ç–æ—Ä–∏ —è–∫—ñ—Å—Ç—å RAG –≤ production?**
A:
```
Key metrics:
- Retrieval precision/recall
- Answer relevancy (RAGAS)
- Response time (p50, p95, p99)
- User feedback (thumbs up/down)
- A/B test results

Tools:
- LangSmith (LangChain)
- Weights & Biases
- Custom dashboards (Grafana)
```

---

## üìã Backup: Hybrid RAG (—è–∫—â–æ –∑–∞–ª–∏—à–∏—Ç—å—Å—è —á–∞—Å)

**–Ø–ö–©–û –Ñ 3-5 –î–û–î–ê–¢–ö–û–í–ò–• –•–í–ò–õ–ò–ù:**

```bash
python rag_demos/hybrid_rag/hybrid_rag_demo.py
```

**–®–í–ò–î–ö–ò–ô –°–¶–ï–ù–ê–†–Ü–ô:**
> "–ë–æ–Ω—É—Å–æ–º –ø–æ–∫–∞–∂—É Hybrid RAG - –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—é sparse (TF-IDF) —ñ dense (FAISS). –ú–∏ –≤–∏–ø—Ä–∞–≤–∏–ª–∏ –±–∞–≥ –≤ RRF algorithm –º–∏–Ω—É–ª–æ–≥–æ —Ç–∏–∂–Ω—è!"

**–ü–û–ö–ê–ó–ê–¢–ò:**
- RRF formula
- Alpha parameter (0.3 vs 0.7)
- –î–æ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è: –≤—Å—ñ scores 0.008
- –ü—ñ—Å–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è: scores —Ä—ñ–∑–Ω—ñ (0.0164, 0.0161, ...)

---

## üì± –ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ –¥–ª—è –°—Ç—É–¥–µ–Ω—Ç—ñ–≤ (After Workshop)

**–©–û –ù–ê–î–ê–¢–ò:**
```
üìÅ Materials:
‚îú‚îÄ‚îÄ WORKSHOP_SUMMARY.md      (full guide)
‚îú‚îÄ‚îÄ All demo scripts
‚îú‚îÄ‚îÄ Benchmark results JSON
‚îú‚îÄ‚îÄ Presentation slides
‚îî‚îÄ‚îÄ Links:
    - ChromaDB docs: https://docs.trychroma.com/
    - CLIP paper: https://arxiv.org/abs/2103.00020
    - Sentence Transformers: https://www.sbert.net/
    - LangChain RAG: https://python.langchain.com/docs/use_cases/question_answering/
```

---

## üéì –ö–Ü–ù–ï–¶–¨ WORKSHOP

**–§–Ü–ù–ê–õ–¨–ù–Ü –°–õ–û–í–ê:**
> "–î—è–∫—É—é –∑–∞ —É–≤–∞–≥—É! –í—Å—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏, –∫–æ–¥ —ñ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—ó –Ω–∞–¥—ñ—à–ª—é –≤–∞–º. –Ø–∫—â–æ –±—É–¥—É—Ç—å –ø–∏—Ç–∞–Ω–Ω—è –ø—ñ—Å–ª—è –≤–æ—Ä–∫—à–æ–ø—É - –ø–∏—à—ñ—Ç—å. –£—Å–ø—ñ—Ö—ñ–≤ –≤ —ñ–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü—ñ—ó RAG —Å–∏—Å—Ç–µ–º!"

**–ü–æ–∫–∞–∑–∞—Ç–∏ QR –∫–æ–¥ –∞–±–æ –∫–æ–Ω—Ç–∞–∫—Ç–∏ –¥–ª—è follow-up questions**

---

**–°—Ç–≤–æ—Ä–µ–Ω–æ**: 26 –∂–æ–≤—Ç–Ω—è 2025
**–í–µ—Ä—Å—ñ—è**: 1.0 - READY FOR WORKSHOP
**–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å**: 50 —Ö–≤–∏–ª–∏–Ω –ø—Ä–∞–∫—Ç–∏–∫–∏
**–§–æ—Ä–º–∞—Ç**: Live demos + explanations

üéâ **–ì–û–¢–û–í–û –î–û –í–û–†–ö–®–û–ü–£ 30 –ñ–û–í–¢–ù–Ø!**
