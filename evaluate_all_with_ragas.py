"""
RAGAS Evaluation –¥–ª—è –≤—Å—ñ—Ö RAG –ø—ñ–¥—Ö–æ–¥—ñ–≤
=======================================

–¶–µ–π —Å–∫—Ä–∏–ø—Ç –æ—Ü—ñ–Ω—é—î –í–°–Ü–• –ø—ñ–¥—Ö–æ–¥—ñ–≤ RAG (Naive, Advanced, Hybrid, Corrective —Ç–æ—â–æ)
–∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é RAGAS metrics –æ–∫—Ä–µ–º–æ –≤—ñ–¥ —ó—Ö –≤–∏–∫–æ–Ω–∞–Ω–Ω—è.

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
1. –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å –≤—Å—ñ demo —Å–∫—Ä–∏–ø—Ç–∏ (–≤–æ–Ω–∏ —Å—Ç–≤–æ—Ä—è—Ç—å JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)
2. –ü–æ—Ç—ñ–º –∑–∞–ø—É—Å—Ç—ñ—Ç—å —Ü–µ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è RAGAS evaluation

–†–µ–∑—É–ª—å—Ç–∞—Ç: –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑ RAGAS –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É
"""

import json
from pathlib import Path
from typing import Dict, List
import sys

# RAGAS imports
try:
    from datasets import Dataset
    from ragas import evaluate
    from ragas.metrics import faithfulness, answer_relevancy
    HAS_RAGAS = True
except ImportError:
    HAS_RAGAS = False
    print("‚ùå RAGAS –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    print("   –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install ragas datasets langchain-openai")
    sys.exit(1)


def load_results_file(file_path: str) -> Dict:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ JSON —Ñ–∞–π–ª—É"""
    path = Path(file_path)
    if not path.exists():
        return None

    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)


def prepare_ragas_dataset(results: Dict) -> Dataset:
    """
    –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ —É —Ñ–æ—Ä–º–∞—Ç—ñ RAGAS Dataset

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ JSON —Ñ–∞–π–ª—É

    Returns:
        Dataset –¥–ª—è RAGAS
    """
    # –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤ JSON
    queries = results.get("queries", [])

    # Hybrid RAG –º–∞—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É: config_results[].queries
    if not queries and "config_results" in results:
        queries = []
        for config in results["config_results"]:
            queries.extend(config.get("queries", []))

    data = {
        "question": [],
        "answer": [],
        "contexts": []
    }

    for query in queries:
        # –ë–µ—Ä–µ–º–æ question (–ø—ñ–¥—Ç—Ä–∏–º–∫–∞ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤)
        question = query.get("question") or query.get("query", "")
        if not question:
            continue

        # –ë–µ—Ä–µ–º–æ answer
        answer = query.get("answer", "")

        # –ë–µ—Ä–µ–º–æ contexts (—è–∫—â–æ —î)
        contexts = query.get("contexts", [])
        if not contexts:
            # –Ø–∫—â–æ contexts –Ω–µ–º–∞—î, –±–µ—Ä–µ–º–æ –∑ sources –∞–±–æ –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ
            sources = query.get("sources", [])
            if sources:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ sources —è–∫ contexts (–Ω–µ —ñ–¥–µ–∞–ª—å–Ω–æ –∞–ª–µ –∫—Ä–∞—â–µ –Ω—ñ–∂ –Ω—ñ—á–æ–≥–æ)
                contexts = [f"Source: {s}" for s in sources]
            else:
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —è–∫—â–æ –Ω–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                continue

        data["question"].append(question)
        data["answer"].append(answer)
        data["contexts"].append(contexts)

    return Dataset.from_dict(data)


def evaluate_rag_approach(
    approach_name: str,
    results: Dict,
    llm,
    embeddings
) -> Dict:
    """
    –û—Ü—ñ–Ω–∏—Ç–∏ –æ–¥–∏–Ω –ø—ñ–¥—Ö—ñ–¥ RAG –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é RAGAS

    Args:
        approach_name: –ù–∞–∑–≤–∞ –ø—ñ–¥—Ö–æ–¥—É (Naive RAG, Advanced RAG —Ç–æ—â–æ)
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ JSON
        llm: LLM –¥–ª—è RAGAS
        embeddings: Embeddings –¥–ª—è RAGAS

    Returns:
        Dict –∑ RAGAS –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    print(f"\n{'='*70}")
    print(f"üìä –û—Ü—ñ–Ω–∫–∞: {approach_name}")
    print(f"{'='*70}")

    try:
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ dataset
        dataset = prepare_ragas_dataset(results)

        if len(dataset) == 0:
            print(f"‚ö†Ô∏è  –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –æ—Ü—ñ–Ω–∫–∏")
            return {"error": "No data"}

        print(f"‚úÖ –ü—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(dataset)} –∑–∞–ø–∏—Ç—ñ–≤")

        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
        metrics = [
            faithfulness,      # –ß–∏ –±–∞–∑—É—î—Ç—å—Å—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ?
            answer_relevancy,  # –ß–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–ø–∏—Ç—É?
        ]

        print("üß™ –ó–∞–ø—É—Å–∫ RAGAS evaluation...")
        print("   –¶–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ 1-2 —Ö–≤–∏–ª–∏–Ω–∏...")

        # –ó–∞–ø—É—Å–∫ evaluation –∑ Ollama
        evaluation_result = evaluate(
            dataset,
            metrics=metrics,
            llm=llm,
            embeddings=embeddings
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        # RAGAS –º–æ–∂–µ –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ —Å–ø–∏—Å–∫–∏ (–ø–æ –æ–¥–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–Ω—é –Ω–∞ –∑–∞–ø–∏—Ç), —Ç–æ–º—É –±–µ—Ä–µ–º–æ —Å–µ—Ä–µ–¥–Ω—î
        # EvaluationResult –æ–±'—î–∫—Ç –ø—ñ–¥—Ç—Ä–∏–º—É—î —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—é, –∞–ª–µ –Ω–µ .get()
        faithfulness_val = evaluation_result["faithfulness"]
        answer_relevancy_val = evaluation_result["answer_relevancy"]

        # –Ø–∫—â–æ —Å–ø–∏—Å–æ–∫ - –±–µ—Ä–µ–º–æ —Å–µ—Ä–µ–¥–Ω—î, —è–∫—â–æ —Å–∫–∞–ª—è—Ä - –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ
        if isinstance(faithfulness_val, list):
            import numpy as np
            faithfulness_val = np.mean(faithfulness_val)
        if isinstance(answer_relevancy_val, list):
            import numpy as np
            answer_relevancy_val = np.mean(answer_relevancy_val)

        ragas_scores = {
            "approach": approach_name,
            "faithfulness": float(faithfulness_val),
            "answer_relevancy": float(answer_relevancy_val),
            "queries_evaluated": len(dataset)
        }

        # –°–µ—Ä–µ–¥–Ω—ñ–π score
        ragas_scores["average_score"] = (
            ragas_scores["faithfulness"] + ragas_scores["answer_relevancy"]
        ) / 2

        print(f"‚úÖ Faithfulness:    {ragas_scores['faithfulness']:.3f}")
        print(f"‚úÖ Answer Relevancy: {ragas_scores['answer_relevancy']:.3f}")
        print(f"‚úÖ Average Score:    {ragas_scores['average_score']:.3f}")

        return ragas_scores

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ü—ñ–Ω–∫–∏: {e}")
        return {"error": str(e)}


def print_comparison_table(all_scores: List[Dict]):
    """–í–∏–≤–µ—Å—Ç–∏ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—É —Ç–∞–±–ª–∏—Ü—é –º–µ—Ç—Ä–∏–∫"""
    print("\n" + "="*90)
    print("üìä –ü–û–†–Ü–í–ù–Ø–õ–¨–ù–ê –¢–ê–ë–õ–ò–¶–Ø RAGAS –ú–ï–¢–†–ò–ö")
    print("="*90)
    print()

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ñ
    print(f"{'–ü—ñ–¥—Ö—ñ–¥':<25} {'Faithfulness':>15} {'Relevancy':>15} {'Average':>15} {'Queries':>10}")
    print("-" * 90)

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å–µ—Ä–µ–¥–Ω—ñ–º score
    sorted_scores = sorted(
        [s for s in all_scores if "error" not in s],
        key=lambda x: x.get("average_score", 0),
        reverse=True
    )

    for scores in sorted_scores:
        approach = scores["approach"]
        faith = scores["faithfulness"]
        relev = scores["answer_relevancy"]
        avg = scores["average_score"]
        queries = scores["queries_evaluated"]

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –µ–º–æ–¥–∂—ñ —Å—Ç–∞—Ç—É—Å—É
        if avg >= 0.85:
            status = "‚úÖ"
        elif avg >= 0.70:
            status = "‚ö†Ô∏è "
        else:
            status = "‚ùå"

        print(f"{status} {approach:<23} {faith:>15.3f} {relev:>15.3f} {avg:>15.3f} {queries:>10}")

    print("="*90)
    print()
    print("–õ–µ–≥–µ–Ω–¥–∞:")
    print("  ‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–æ (‚â•0.85) - –≥–æ—Ç–æ–≤–æ –¥–ª—è production")
    print("  ‚ö†Ô∏è  –ü—Ä–∏–π–Ω—è—Ç–Ω–æ (0.70-0.85) - –ø–æ—Ç—Ä—ñ–±–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è")
    print("  ‚ùå –ù–∏–∑—å–∫–æ (<0.70) - –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏")
    print()


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è - –æ—Ü—ñ–Ω—é—î –≤—Å—ñ RAG –ø—ñ–¥—Ö–æ–¥–∏"""
    print("="*90)
    print(" RAGAS EVALUATION –î–õ–Ø –í–°–Ü–• RAG –ü–Ü–î–•–û–î–Ü–í")
    print("="*90)
    print()

    if not HAS_RAGAS:
        return

    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è OpenAI –¥–ª—è RAGAS
    print(" –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è OpenAI –¥–ª—è RAGAS...")
    print("   –ú–æ–¥–µ–ª—å: gpt-4o-mini (—à–≤–∏–¥–∫–æ, –Ω–µ–¥–æ—Ä–æ–≥–æ)")
    print()

    try:
        from langchain_openai import ChatOpenAI, OpenAIEmbeddings
        openai_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        openai_embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ OpenAI: {e}")
        print("   –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—å —â–æ OPENAI_API_KEY –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        sys.exit(1)

    # –°–ø–∏—Å–æ–∫ –ø—ñ–¥—Ö–æ–¥—ñ–≤ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
    approaches = [
        ("Naive RAG", "results/naive_rag_results.json"),
        ("Advanced RAG", "results/advanced_rag_results.json"),
        ("Hybrid RAG (All)", "results/hybrid_rag_all_results.json"),
        ("Corrective RAG", "results/corrective_rag_results.json"),
        # ("Multimodal RAG", "results/multimodal_rag_results.json"),  # –ü–æ–∫–∏ –Ω–µ–º–∞—î
    ]

    all_scores = []

    # –û—Ü—ñ–Ω—é—î–º–æ –∫–æ–∂–µ–Ω –ø—ñ–¥—Ö—ñ–¥
    for approach_name, results_file in approaches:
        print(f"\n{'='*90}")
        print(f"üîç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {results_file}")

        results = load_results_file(results_file)

        if results is None:
            print(f"  –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {results_file}")
            print(f"   –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π demo —Å–∫—Ä–∏–ø—Ç")
            continue

        # –û—Ü—ñ–Ω—é—î–º–æ —Ü–µ–π –ø—ñ–¥—Ö—ñ–¥
        scores = evaluate_rag_approach(
            approach_name,
            results,
            openai_llm,
            openai_embeddings
        )

        if "error" not in scores:
            all_scores.append(scores)

    # –í–∏–≤–æ–¥–∏–º–æ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—É —Ç–∞–±–ª–∏—Ü—é
    if all_scores:
        print_comparison_table(all_scores)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        output = {
            "ragas_comparison": all_scores,
            "summary": {
                "total_approaches": len(all_scores),
                "best_approach": max(all_scores, key=lambda x: x["average_score"])["approach"],
                "best_score": max(all_scores, key=lambda x: x["average_score"])["average_score"]
            }
        }

        output_file = "results/ragas_comparison.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f" –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_file}")

        # –í–∏—Å–Ω–æ–≤–∫–∏
        best = output["summary"]["best_approach"]
        best_score = output["summary"]["best_score"]

        print()
        print("="*90)
        print(" –í–ò–°–ù–û–í–ö–ò")
        print("="*90)
        print(f"–ù–∞–π–∫—Ä–∞—â–∏–π –ø—ñ–¥—Ö—ñ–¥: {best} (score: {best_score:.3f})")
        print()

        if best_score >= 0.85:
            print(" –í—ñ–¥–º—ñ–Ω–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è production.")
        elif best_score >= 0.70:
            print("  –ü—Ä–∏–π–Ω—è—Ç–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∞–ª–µ —î –ø—Ä–æ—Å—Ç—ñ—Ä –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è.")
        else:
            print(" –ù–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å. –†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –±—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥.")

        print()
        print("="*90)
    else:
        print("\n –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ü—ñ–Ω–∏—Ç–∏ –∂–æ–¥–µ–Ω –ø—ñ–¥—Ö—ñ–¥")
        print("   –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—å —â–æ demo —Å–∫—Ä–∏–ø—Ç–∏ –±—É–ª–∏ –∑–∞–ø—É—â–µ–Ω—ñ:")
        print("   - python rag_demos/naive_rag/naive_rag_demo.py")
        print("   - python rag_demos/advanced_rag/advanced_rag_demo.py")
        print("   - —Ç–æ—â–æ...")


if __name__ == "__main__":
    main()
