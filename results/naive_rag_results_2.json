{
  "system_name": "Naive RAG",
  "total_documents": 50,
  "total_chunks": 0,
  "chunk_size": 500,
  "chunk_overlap": 100,
  "llm_model": "fallback (без LLM)",
  "queries": [
    {
      "question": "What is Retrieval-Augmented Generation (RAG)?",
      "answer": "s.\n5.1.3\nRetrieval-Augmented Generation. Typically, retrieval-augmented generation (RAG) [109, 165,\n278] follows a retrieve-then-read pipeline, where relevant knowledge is firstly retrieved by a retriever\n[146] from external sources, and then the final response is generated by a generator conditioning\non both user query and retrieved documents. By decoupling external knowledge from LLM, RAG\ncan effectively alleviate the hallucination caused by the knowledge gap without affecting the\n\nA\nComprehensive\nSurvey\nof\nRetrieval-Augmented\nGeneration\n(RAG):\nEvolution,\nCurrent\nLandscape and Future Directions\nShailja Gupta (Carnegie Mellon University, USA)\nRajesh Ranjan (Carnegie Mellon University, USA)\nSurya Narayan Singh (BIT Sindri, India)\nAbstract\nThis paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its\nevolution from foundational concepts to the current state of the art. RAG combines retrieval mechanisms\n\nacross various applications. However, there is a gap in a sufficient survey of this space tracking\nthe evolution and recent changes in this space. The current survey intends to fill this gap.\n1.2 Overview of Retrieval-Augmented Generation (RAG)\nRetrieval-Augmented Generation (RAG) is an emerging hybrid architecture designed to address the\nlimitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,",
      "relevant_chunks": 8,
      "sources": [
        "2311.05232.pdf_chunk_222",
        "2410.12837.pdf_chunk_0",
        "2410.12837.pdf_chunk_10"
      ],
      "scores": [
        0.3565968871116638,
        0.491000771522522,
        0.5051963925361633
      ],
      "contexts": [
        "s.\n5.1.3\nRetrieval-Augmented Generation. Typically, retrieval-augmented generation (RAG) [109, 165,\n278] follows a retrieve-then-read pipeline, where relevant knowledge is firstly retrieved by a retriever\n[146] from external sources, and then the final response is generated by a generator conditioning\non both user query and retrieved documents. By decoupling external knowledge from LLM, RAG\ncan effectively alleviate the hallucination caused by the knowledge gap without affecting the",
        "A\nComprehensive\nSurvey\nof\nRetrieval-Augmented\nGeneration\n(RAG):\nEvolution,\nCurrent\nLandscape and Future Directions\nShailja Gupta (Carnegie Mellon University, USA)\nRajesh Ranjan (Carnegie Mellon University, USA)\nSurya Narayan Singh (BIT Sindri, India)\nAbstract\nThis paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its\nevolution from foundational concepts to the current state of the art. RAG combines retrieval mechanisms",
        "across various applications. However, there is a gap in a sufficient survey of this space tracking\nthe evolution and recent changes in this space. The current survey intends to fill this gap.\n1.2 Overview of Retrieval-Augmented Generation (RAG)\nRetrieval-Augmented Generation (RAG) is an emerging hybrid architecture designed to address the\nlimitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,"
      ],
      "execution_time": 0.18059706687927246,
      "category": "definition",
      "query_id": 1,
      "difficulty": "easy"
    },
    {
      "question": "What are the main components of a RAG system?",
      "answer": "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_3",
        "RAG_Survey_2023.pdf_chunk_3",
        "2312.10997.pdf_chunk_12"
      ],
      "scores": [
        0.6435354948043823,
        0.6435354948043823,
        0.7019728422164917
      ],
      "contexts": [
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.2049112319946289,
      "category": "definition",
      "query_id": 2,
      "difficulty": "easy"
    },
    {
      "question": "How does RAG differ from traditional LLMs?",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.5691207647323608,
        0.5691207647323608,
        0.5888128876686096
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.2309257984161377,
      "category": "definition",
      "query_id": 3,
      "difficulty": "medium"
    },
    {
      "question": "What is the purpose of the retrieval component in RAG?",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\ndaptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "2312.10997.pdf_chunk_51"
      ],
      "scores": [
        0.5858248472213745,
        0.5858248472213745,
        0.6513220071792603
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning"
      ],
      "execution_time": 0.26476144790649414,
      "category": "definition",
      "query_id": 4,
      "difficulty": "easy"
    },
    {
      "question": "Explain the concept of grounding in RAG systems",
      "answer": "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_17",
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.8684146404266357,
        0.8796253204345703,
        0.8796253204345703
      ],
      "contexts": [
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.18140935897827148,
      "category": "definition",
      "query_id": 5,
      "difficulty": "medium"
    },
    {
      "question": "How does the retrieval mechanism work in RAG systems?",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\ndaptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_51"
      ],
      "scores": [
        0.5705474615097046,
        0.5705474615097046,
        0.571954071521759
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning"
      ],
      "execution_time": 0.17310476303100586,
      "category": "technical",
      "query_id": 6,
      "difficulty": "medium"
    },
    {
      "question": "What is the role of embeddings in RAG?",
      "answer": "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_3",
        "RAG_Survey_2023.pdf_chunk_3",
        "2401.05856.pdf_chunk_53"
      ],
      "scores": [
        0.7198559641838074,
        0.7198559641838074,
        0.73445063829422
      ],
      "contexts": [
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular"
      ],
      "execution_time": 0.17122840881347656,
      "category": "technical",
      "query_id": 7,
      "difficulty": "medium"
    },
    {
      "question": "Explain how dense retrieval works in RAG",
      "answer": "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_53",
        "2312.10997.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_34"
      ],
      "scores": [
        0.5842231512069702,
        0.6558966636657715,
        0.6558966636657715
      ],
      "contexts": [
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure."
      ],
      "execution_time": 0.1745891571044922,
      "category": "technical",
      "query_id": 8,
      "difficulty": "hard"
    },
    {
      "question": "What is the difference between sparse and dense retrieval?",
      "answer": "Retrieval : Sparse and dense embedding\napproaches capture different relevance features and can ben-\nefit from each other by leveraging complementary relevance\ninformation. For instance, sparse retrieval models can be used\n6https://github.com/aurelio-labs/semantic-router\n7https://huggingface.co/spaces/mteb/leaderboard\nto provide initial search results for training dense retrieval\nmodels. Additionally, pre-training language models (PLMs)\ncan be utilized to learn term weights to enhance sparse\n\nRetrieval : Sparse and dense embedding\napproaches capture different relevance features and can ben-\nefit from each other by leveraging complementary relevance\ninformation. For instance, sparse retrieval models can be used\n6https://github.com/aurelio-labs/semantic-router\n7https://huggingface.co/spaces/mteb/leaderboard\nto provide initial search results for training dense retrieval\nmodels. Additionally, pre-training language models (PLMs)\ncan be utilized to learn term weights to enhance sparse\n\ne models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_107",
        "RAG_Survey_2023.pdf_chunk_107",
        "RAG_Survey_2023.pdf_chunk_82"
      ],
      "scores": [
        0.9350752830505371,
        0.9350752830505371,
        0.9407033324241638
      ],
      "contexts": [
        "Retrieval : Sparse and dense embedding\napproaches capture different relevance features and can ben-\nefit from each other by leveraging complementary relevance\ninformation. For instance, sparse retrieval models can be used\n6https://github.com/aurelio-labs/semantic-router\n7https://huggingface.co/spaces/mteb/leaderboard\nto provide initial search results for training dense retrieval\nmodels. Additionally, pre-training language models (PLMs)\ncan be utilized to learn term weights to enhance sparse",
        "Retrieval : Sparse and dense embedding\napproaches capture different relevance features and can ben-\nefit from each other by leveraging complementary relevance\ninformation. For instance, sparse retrieval models can be used\n6https://github.com/aurelio-labs/semantic-router\n7https://huggingface.co/spaces/mteb/leaderboard\nto provide initial search results for training dense retrieval\nmodels. Additionally, pre-training language models (PLMs)\ncan be utilized to learn term weights to enhance sparse",
        "e models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,"
      ],
      "execution_time": 0.17298603057861328,
      "category": "technical",
      "query_id": 9,
      "difficulty": "medium"
    },
    {
      "question": "How does chunking strategy affect RAG performance?",
      "answer": "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular\n\nand affect the relevance of retrieved information [224], thereby affecting the performance of\nLLMs. Fixed-size chunking, which typically breaks down the documents into chunks of a specified\nlength such as 100-word paragraphs, serves as the most crude and prevalent strategy of chunking,\nwhich is widely used in RAG systems [24, 109, 165]. Considering fixed-size chunking falls short in\ncapture structure and dependency of lengthy documents, Sarthi et al. [267] proposed RAPTOR, an\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_53",
        "2311.05232.pdf_chunk_324",
        "2312.10997.pdf_chunk_12"
      ],
      "scores": [
        0.6041367053985596,
        0.6812703609466553,
        0.8070950508117676
      ],
      "contexts": [
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
        "and affect the relevance of retrieved information [224], thereby affecting the performance of\nLLMs. Fixed-size chunking, which typically breaks down the documents into chunks of a specified\nlength such as 100-word paragraphs, serves as the most crude and prevalent strategy of chunking,\nwhich is widely used in RAG systems [24, 109, 165]. Considering fixed-size chunking falls short in\ncapture structure and dependency of lengthy documents, Sarthi et al. [267] proposed RAPTOR, an",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.17169404029846191,
      "category": "technical",
      "query_id": 10,
      "difficulty": "hard"
    },
    {
      "question": "What is the role of the retriever in RAG architecture?",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nRAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "2404.16130.pdf_chunk_16"
      ],
      "scores": [
        0.7307579517364502,
        0.7307579517364502,
        0.7438505291938782
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single"
      ],
      "execution_time": 0.17722034454345703,
      "category": "technical",
      "query_id": 41,
      "difficulty": "easy"
    },
    {
      "question": "Explain the concept of semantic search in RAG",
      "answer": "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nunderstanding the potential of RAG and its trajectory in the field of natural language processing.\nFigure 1: Trends in RAG captured from recent research papers\nKeywords: Retrieval-Augmented Generation (RAG), Information Retrieval, Natural Language Processing\n(NLP), Artificial Intelligence (AI), Machine Learning (ML), Large Language Model (LLM).\nIntroduction\n1.1 Introduction of Natural Language Generation (NLG)",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_34",
        "2410.12837.pdf_chunk_4"
      ],
      "scores": [
        0.6841729879379272,
        0.6841729879379272,
        0.7024968862533569
      ],
      "contexts": [
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "understanding the potential of RAG and its trajectory in the field of natural language processing.\nFigure 1: Trends in RAG captured from recent research papers\nKeywords: Retrieval-Augmented Generation (RAG), Information Retrieval, Natural Language Processing\n(NLP), Artificial Intelligence (AI), Machine Learning (ML), Large Language Model (LLM).\nIntroduction\n1.1 Introduction of Natural Language Generation (NLG)"
      ],
      "execution_time": 0.17174434661865234,
      "category": "technical",
      "query_id": 42,
      "difficulty": "medium"
    },
    {
      "question": "How do attention mechanisms work in RAG systems?",
      "answer": "etrieved documents, either independently (pointwise) or by comparing document pairs (pairwise). RAG\nsystems utilize self-attention within the LLM to manage context and relevance across different parts of the\ninput and retrieved text. Cross-attention mechanisms are used when integrating retrieved information into\nthe generative model, ensuring that the most relevant pieces of information are emphasized during\ngeneration.\n2.3 Generator Mechanisms in RAG Systems\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
      "relevant_chunks": 8,
      "sources": [
        "2410.12837.pdf_chunk_53",
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11"
      ],
      "scores": [
        0.7153918743133545,
        0.9045204520225525,
        0.9045204520225525
      ],
      "contexts": [
        "etrieved documents, either independently (pointwise) or by comparing document pairs (pairwise). RAG\nsystems utilize self-attention within the LLM to manage context and relevance across different parts of the\ninput and retrieved text. Cross-attention mechanisms are used when integrating retrieved information into\nthe generative model, ensuring that the most relevant pieces of information are emphasized during\ngeneration.\n2.3 Generator Mechanisms in RAG Systems",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG."
      ],
      "execution_time": 0.17917084693908691,
      "category": "technical",
      "query_id": 43,
      "difficulty": "hard"
    },
    {
      "question": "What is the purpose of document encoding in RAG?",
      "answer": "imitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,\nwhich retrieves relevant documents or information from an external knowledge source, and (ii) a\ngeneration module, which processes this information to generate human-like text (Lewis et al. 2020). This\ncombination allows RAG models to not only generate fluent text but also ground their outputs in\nreal-world, up-to-date data.\n\nRAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single\n\nND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
      "relevant_chunks": 8,
      "sources": [
        "2410.12837.pdf_chunk_11",
        "2404.16130.pdf_chunk_16",
        "2401.05856.pdf_chunk_53"
      ],
      "scores": [
        0.7416269183158875,
        0.7488084435462952,
        0.7599116563796997
      ],
      "contexts": [
        "imitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,\nwhich retrieves relevant documents or information from an external knowledge source, and (ii) a\ngeneration module, which processes this information to generate human-like text (Lewis et al. 2020). This\ncombination allows RAG models to not only generate fluent text but also ground their outputs in\nreal-world, up-to-date data.",
        "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single",
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular"
      ],
      "execution_time": 0.17371916770935059,
      "category": "technical",
      "query_id": 44,
      "difficulty": "medium"
    },
    {
      "question": "How does RAG handle out-of-domain queries?",
      "answer": "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single\n\ns. RAG bridges this information\ngap by sourcing and incorporating knowledge from external\ndatabases. In this case, it gathers relevant news articles related\nto the user’s query. These articles, combined with the original\nquestion, form a comprehensive prompt that empowers LLMs\nto generate a well-informed answer.\nThe RAG research paradigm is continuously evolving, and\nwe categorize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite\n\ns. RAG bridges this information\ngap by sourcing and incorporating knowledge from external\ndatabases. In this case, it gathers relevant news articles related\nto the user’s query. These articles, combined with the original\nquestion, form a comprehensive prompt that empowers LLMs\nto generate a well-informed answer.\nThe RAG research paradigm is continuously evolving, and\nwe categorize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite",
      "relevant_chunks": 8,
      "sources": [
        "2404.16130.pdf_chunk_16",
        "2312.10997.pdf_chunk_21",
        "RAG_Survey_2023.pdf_chunk_21"
      ],
      "scores": [
        0.650292158126831,
        0.7140680551528931,
        0.7140680551528931
      ],
      "contexts": [
        "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single",
        "s. RAG bridges this information\ngap by sourcing and incorporating knowledge from external\ndatabases. In this case, it gathers relevant news articles related\nto the user’s query. These articles, combined with the original\nquestion, form a comprehensive prompt that empowers LLMs\nto generate a well-informed answer.\nThe RAG research paradigm is continuously evolving, and\nwe categorize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite",
        "s. RAG bridges this information\ngap by sourcing and incorporating knowledge from external\ndatabases. In this case, it gathers relevant news articles related\nto the user’s query. These articles, combined with the original\nquestion, form a comprehensive prompt that empowers LLMs\nto generate a well-informed answer.\nThe RAG research paradigm is continuously evolving, and\nwe categorize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite"
      ],
      "execution_time": 0.16613245010375977,
      "category": "technical",
      "query_id": 45,
      "difficulty": "hard"
    },
    {
      "question": "What is Self-RAG and how does it differ from standard RAG?",
      "answer": "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_3",
        "RAG_Survey_2023.pdf_chunk_3",
        "2312.10997.pdf_chunk_12"
      ],
      "scores": [
        0.7595343589782715,
        0.7595343589782715,
        0.7744525671005249
      ],
      "contexts": [
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.16927599906921387,
      "category": "approaches",
      "query_id": 11,
      "difficulty": "hard"
    },
    {
      "question": "Explain the concept of Corrective RAG (CRAG)",
      "answer": "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_17",
        "2312.10997.pdf_chunk_3",
        "RAG_Survey_2023.pdf_chunk_3"
      ],
      "scores": [
        0.7868821620941162,
        0.8301808834075928,
        0.8301808834075928
      ],
      "contexts": [
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-"
      ],
      "execution_time": 0.1690201759338379,
      "category": "approaches",
      "query_id": 12,
      "difficulty": "hard"
    },
    {
      "question": "How does Hybrid RAG combine different retrieval methods?",
      "answer": "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_11"
      ],
      "scores": [
        0.5173429250717163,
        0.5173429250717163,
        0.6191028952598572
      ],
      "contexts": [
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG."
      ],
      "execution_time": 0.17043137550354004,
      "category": "approaches",
      "query_id": 13,
      "difficulty": "medium"
    },
    {
      "question": "What is the advantage of query rewriting in RAG?",
      "answer": "0], the original\nquery is abstracted to generate a high-level concept question\n(step-back question). In the RAG system, both the step-back\nquestion and the original query are used for retrieval, and both\nthe results are utilized as the basis for language model answer\ngeneration.\n3) Query Routing: Based on varying queries, routing to\ndistinct RAG pipeline,which is suitable for a versatile RAG\nsystem designed to accommodate diverse scenarios.\nMetadata Router/ Filter.\n\n0], the original\nquery is abstracted to generate a high-level concept question\n(step-back question). In the RAG system, both the step-back\nquestion and the original query are used for retrieval, and both\nthe results are utilized as the basis for language model answer\ngeneration.\n3) Query Routing: Based on varying queries, routing to\ndistinct RAG pipeline,which is suitable for a versatile RAG\nsystem designed to accommodate diverse scenarios.\nMetadata Router/ Filter.\n\nRAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_102",
        "RAG_Survey_2023.pdf_chunk_102",
        "2404.16130.pdf_chunk_16"
      ],
      "scores": [
        0.7193372249603271,
        0.7193372249603271,
        0.7328335046768188
      ],
      "contexts": [
        "0], the original\nquery is abstracted to generate a high-level concept question\n(step-back question). In the RAG system, both the step-back\nquestion and the original query are used for retrieval, and both\nthe results are utilized as the basis for language model answer\ngeneration.\n3) Query Routing: Based on varying queries, routing to\ndistinct RAG pipeline,which is suitable for a versatile RAG\nsystem designed to accommodate diverse scenarios.\nMetadata Router/ Filter.",
        "0], the original\nquery is abstracted to generate a high-level concept question\n(step-back question). In the RAG system, both the step-back\nquestion and the original query are used for retrieval, and both\nthe results are utilized as the basis for language model answer\ngeneration.\n3) Query Routing: Based on varying queries, routing to\ndistinct RAG pipeline,which is suitable for a versatile RAG\nsystem designed to accommodate diverse scenarios.\nMetadata Router/ Filter.",
        "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single"
      ],
      "execution_time": 0.16761255264282227,
      "category": "approaches",
      "query_id": 14,
      "difficulty": "medium"
    },
    {
      "question": "Explain the re-ranking stage in Advanced RAG",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_17"
      ],
      "scores": [
        0.6618868112564087,
        0.6618868112564087,
        0.6805018186569214
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing"
      ],
      "execution_time": 0.17901062965393066,
      "category": "approaches",
      "query_id": 15,
      "difficulty": "medium"
    },
    {
      "question": "What is iterative RAG and when is it beneficial?",
      "answer": "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12",
        "2312.10997.pdf_chunk_11"
      ],
      "scores": [
        0.6422126889228821,
        0.6422126889228821,
        0.651779294013977
      ],
      "contexts": [
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG."
      ],
      "execution_time": 0.17188334465026855,
      "category": "approaches",
      "query_id": 46,
      "difficulty": "hard"
    },
    {
      "question": "Explain the concept of fusion in hybrid RAG systems",
      "answer": "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-\n\ne present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_3",
        "RAG_Survey_2023.pdf_chunk_3",
        "2401.05856.pdf_chunk_17"
      ],
      "scores": [
        0.7569240927696228,
        0.7569240927696228,
        0.7634080052375793
      ],
      "contexts": [
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK"
      ],
      "execution_time": 0.17312145233154297,
      "category": "approaches",
      "query_id": 47,
      "difficulty": "medium"
    },
    {
      "question": "What is adaptive retrieval in Self-RAG?",
      "answer": "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning\n\ndaptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning\n\nactivates the retrieval system\nto collect relevant information, thus optimizing the retrieval\ncycle. Self-RAG [25] introduces “reflection tokens” that allow\nthe model to introspect its outputs. These tokens come in\ntwo varieties: “retrieve” and “critic”. The model autonomously\ndecides when to activate retrieval, or alternatively, a predefined\nthreshold may trigger the process. During retrieval, the gen-\nerator conducts a fragment-level beam search across multiple",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_51",
        "RAG_Survey_2023.pdf_chunk_51",
        "RAG_Survey_2023.pdf_chunk_145"
      ],
      "scores": [
        0.44020766019821167,
        0.44020766019821167,
        0.5922336578369141
      ],
      "contexts": [
        "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning",
        "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning",
        "activates the retrieval system\nto collect relevant information, thus optimizing the retrieval\ncycle. Self-RAG [25] introduces “reflection tokens” that allow\nthe model to introspect its outputs. These tokens come in\ntwo varieties: “retrieve” and “critic”. The model autonomously\ndecides when to activate retrieval, or alternatively, a predefined\nthreshold may trigger the process. During retrieval, the gen-\nerator conducts a fragment-level beam search across multiple"
      ],
      "execution_time": 0.17642784118652344,
      "category": "approaches",
      "query_id": 48,
      "difficulty": "hard"
    },
    {
      "question": "How does context enrichment improve RAG performance?",
      "answer": "ieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\n\nieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\n\nlely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_17",
        "RAG_Survey_2023.pdf_chunk_17",
        "RAG_Survey_2023.pdf_chunk_174"
      ],
      "scores": [
        0.5781159400939941,
        0.5781159400939941,
        0.5849909782409668
      ],
      "contexts": [
        "ieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing",
        "ieval”, “Generation” and “Augmentation”, and\ndelve into their synergies, elucidating how these com-\nponents intricately collaborate to form a cohesive and\neffective RAG framework.\n• We have summarized the current assessment methods of\nRAG, covering 26 tasks, nearly 50 datasets, outlining\nthe evaluation objectives and metrics, as well as the\ncurrent evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing",
        "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during"
      ],
      "execution_time": 0.1706101894378662,
      "category": "approaches",
      "query_id": 49,
      "difficulty": "medium"
    },
    {
      "question": "What is the role of web search in Corrective RAG?",
      "answer": "he efficacy of RAG systems. Effective retrieval depends not only on the clarity of the user queries\nbut also on the quality and comprehensiveness of the sources from which information is retrieved.\nWhen these sources contain factually incorrect or outdated information, the risk of retrieval failures\nincreases significantly, potentially leading to the generation of incorrect or misleading information.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
      "relevant_chunks": 8,
      "sources": [
        "2311.05232.pdf_chunk_314",
        "2312.10997.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_34"
      ],
      "scores": [
        0.6715764999389648,
        0.7954348921775818,
        0.7954348921775818
      ],
      "contexts": [
        "he efficacy of RAG systems. Effective retrieval depends not only on the clarity of the user queries\nbut also on the quality and comprehensiveness of the sources from which information is retrieved.\nWhen these sources contain factually incorrect or outdated information, the risk of retrieval failures\nincreases significantly, potentially leading to the generation of incorrect or misleading information.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure."
      ],
      "execution_time": 0.17028307914733887,
      "category": "approaches",
      "query_id": 50,
      "difficulty": "medium"
    },
    {
      "question": "What metrics should be used to evaluate RAG systems?",
      "answer": "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-\n\nlated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_168",
        "RAG_Survey_2023.pdf_chunk_168",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.3914785385131836,
        0.3914785385131836,
        0.5245622396469116
      ],
      "contexts": [
        "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-",
        "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.17560887336730957,
      "category": "evaluation",
      "query_id": 16,
      "difficulty": "medium"
    },
    {
      "question": "How do you measure faithfulness in RAG outputs?",
      "answer": "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-\n\nlated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_168",
        "RAG_Survey_2023.pdf_chunk_168",
        "2312.10997.pdf_chunk_12"
      ],
      "scores": [
        0.7754963636398315,
        0.7754963636398315,
        0.8567644357681274
      ],
      "contexts": [
        "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-",
        "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.16968131065368652,
      "category": "evaluation",
      "query_id": 17,
      "difficulty": "hard"
    },
    {
      "question": "What is RAGAS and how is it used for RAG evaluation?",
      "answer": "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_3"
      ],
      "scores": [
        0.5427648425102234,
        0.5427648425102234,
        0.5594353675842285
      ],
      "contexts": [
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-"
      ],
      "execution_time": 0.17255711555480957,
      "category": "evaluation",
      "query_id": 18,
      "difficulty": "hard"
    },
    {
      "question": "Explain the difference between retrieval and generation metrics",
      "answer": "ty\nGeneration Quality\nContext Relevance\nFaithfulness\nAnswer Relevance\n*\n*\n*\nCRUD†\nRetrieval Quality\nGeneration Quality\nCreative Generation\nKnowledge-intensive QA\nError Correction\nSummarization\nBLEU\nROUGE-L\nBertScore\nRAGQuestEval\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\n\nty\nGeneration Quality\nContext Relevance\nFaithfulness\nAnswer Relevance\n*\n*\n*\nCRUD†\nRetrieval Quality\nGeneration Quality\nCreative Generation\nKnowledge-intensive QA\nError Correction\nSummarization\nBLEU\nROUGE-L\nBertScore\nRAGQuestEval\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\n\nmain evaluation objectives include:\nRetrieval Quality. Evaluating the retrieval quality is crucial\nfor determining the effectiveness of the context sourced by\nthe retriever component. Standard metrics from the domains\nof search engines, recommendation systems, and information\nretrieval systems are employed to measure the performance of\nthe RAG retrieval module. Metrics such as Hit Rate, MRR, and\nNDCG are commonly utilized for this purpose [161], [162].\nGeneration Quality.",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_180",
        "RAG_Survey_2023.pdf_chunk_180",
        "2312.10997.pdf_chunk_152"
      ],
      "scores": [
        0.6652383208274841,
        0.6652383208274841,
        0.7308374643325806
      ],
      "contexts": [
        "ty\nGeneration Quality\nContext Relevance\nFaithfulness\nAnswer Relevance\n*\n*\n*\nCRUD†\nRetrieval Quality\nGeneration Quality\nCreative Generation\nKnowledge-intensive QA\nError Correction\nSummarization\nBLEU\nROUGE-L\nBertScore\nRAGQuestEval\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these",
        "ty\nGeneration Quality\nContext Relevance\nFaithfulness\nAnswer Relevance\n*\n*\n*\nCRUD†\nRetrieval Quality\nGeneration Quality\nCreative Generation\nKnowledge-intensive QA\nError Correction\nSummarization\nBLEU\nROUGE-L\nBertScore\nRAGQuestEval\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these",
        "main evaluation objectives include:\nRetrieval Quality. Evaluating the retrieval quality is crucial\nfor determining the effectiveness of the context sourced by\nthe retriever component. Standard metrics from the domains\nof search engines, recommendation systems, and information\nretrieval systems are employed to measure the performance of\nthe RAG retrieval module. Metrics such as Hit Rate, MRR, and\nNDCG are commonly utilized for this purpose [161], [162].\nGeneration Quality."
      ],
      "execution_time": 0.16377687454223633,
      "category": "evaluation",
      "query_id": 19,
      "difficulty": "medium"
    },
    {
      "question": "How can we detect hallucinations in RAG systems?",
      "answer": "LM\nhallucinations in depth (§3), followed by a review of various strategies and benchmarks employed\nfor the reliable detection of hallucinations in LLMs (§4). We then detail a spectrum of approaches\ndesigned to mitigate these hallucinations (§5). Concluding, we delve into the challenges faced by\ncurrent RAG systems (§6) and delineate potential pathways for forthcoming research (§7).\n2\nDEFINITIONS\nFor the sake of a comprehensive understanding of hallucinations in LLMs, we commence with a\n\nrvey\nundertakes an in-depth analysis of these challenges, aiming to provide valuable insights aimed\nat developing more robust RAG systems. We also highlight several promising avenues for future\nresearch, such as hallucinations in large vision-language models and understanding of knowledge\nboundaries in LLM hallucinations, paving the way for forthcoming research in the field.\nComparing with Existing Surveys. As hallucination stands out as a major challenge in gener-\n\ng\nthem. Recognizing the multifaceted sources of LLM hallucinations, our survey identifies potential\ncontributors into three main aspects: data, training, and inference stages. This categorization allows\nus to span a broad spectrum of factors, providing a holistic view of the origins and mechanisms by\nwhich hallucinations may arise within LLM systems. Furthermore, we comprehensively outline a\nvariety of effective detection methods specifically devised for detecting hallucinations in LLMs, as",
      "relevant_chunks": 8,
      "sources": [
        "2311.05232.pdf_chunk_32",
        "2311.05232.pdf_chunk_26",
        "2311.05232.pdf_chunk_22"
      ],
      "scores": [
        0.4332897961139679,
        0.7188464403152466,
        0.7620916366577148
      ],
      "contexts": [
        "LM\nhallucinations in depth (§3), followed by a review of various strategies and benchmarks employed\nfor the reliable detection of hallucinations in LLMs (§4). We then detail a spectrum of approaches\ndesigned to mitigate these hallucinations (§5). Concluding, we delve into the challenges faced by\ncurrent RAG systems (§6) and delineate potential pathways for forthcoming research (§7).\n2\nDEFINITIONS\nFor the sake of a comprehensive understanding of hallucinations in LLMs, we commence with a",
        "rvey\nundertakes an in-depth analysis of these challenges, aiming to provide valuable insights aimed\nat developing more robust RAG systems. We also highlight several promising avenues for future\nresearch, such as hallucinations in large vision-language models and understanding of knowledge\nboundaries in LLM hallucinations, paving the way for forthcoming research in the field.\nComparing with Existing Surveys. As hallucination stands out as a major challenge in gener-",
        "g\nthem. Recognizing the multifaceted sources of LLM hallucinations, our survey identifies potential\ncontributors into three main aspects: data, training, and inference stages. This categorization allows\nus to span a broad spectrum of factors, providing a holistic view of the origins and mechanisms by\nwhich hallucinations may arise within LLM systems. Furthermore, we comprehensively outline a\nvariety of effective detection methods specifically devised for detecting hallucinations in LLMs, as"
      ],
      "execution_time": 0.17026829719543457,
      "category": "evaluation",
      "query_id": 20,
      "difficulty": "hard"
    },
    {
      "question": "What is the Lost in the Middle problem in RAG?",
      "answer": "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_17",
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11"
      ],
      "scores": [
        0.8222663998603821,
        0.8569352030754089,
        0.8569352030754089
      ],
      "contexts": [
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG."
      ],
      "execution_time": 0.16885995864868164,
      "category": "challenges",
      "query_id": 21,
      "difficulty": "hard"
    },
    {
      "question": "How does context length affect RAG performance?",
      "answer": "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during\n\nlely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during\n\nthat are closely related to these bottlenecks: contextual awareness and contextual alignment. Each\nplays an important role in ensuring the reliability and credibility of the RAG system.\n6.2.1\nContextual Awareness. Contextual awareness involves understanding and effectively utilizing\ncontextual information retrieved. This section discusses the key factors that impact the LLM’s\nability to maintain contextual awareness, which can be categorized into three main parts: (1) the",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_174",
        "RAG_Survey_2023.pdf_chunk_174",
        "2311.05232.pdf_chunk_335"
      ],
      "scores": [
        0.5898421406745911,
        0.5898421406745911,
        0.7726854085922241
      ],
      "contexts": [
        "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during",
        "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during",
        "that are closely related to these bottlenecks: contextual awareness and contextual alignment. Each\nplays an important role in ensuring the reliability and credibility of the RAG system.\n6.2.1\nContextual Awareness. Contextual awareness involves understanding and effectively utilizing\ncontextual information retrieved. This section discusses the key factors that impact the LLM’s\nability to maintain contextual awareness, which can be categorized into three main parts: (1) the"
      ],
      "execution_time": 0.16962170600891113,
      "category": "challenges",
      "query_id": 22,
      "difficulty": "medium"
    },
    {
      "question": "What are the common failure modes of RAG systems?",
      "answer": "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK\n\nng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the\n\nints that occur when engineering a RAG\nsystem? (section 5) We present an empirical experiment using\nthe BioASQ data set to report on potential failure points. The\nexperiment involved 15,000 documents and 1000 question\narXiv:2401.05856v1  [cs.SE]  11 Jan 2024\nCAIN 2024, April 2024, Lisbon, Portugal\nScott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\nand answer pairs. We indexed all documents then ran the\nqueries and stored the generated responses using GPT-4.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_17",
        "2401.05856.pdf_chunk_13",
        "2401.05856.pdf_chunk_15"
      ],
      "scores": [
        0.47590649127960205,
        0.49755412340164185,
        0.724438488483429
      ],
      "contexts": [
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
        "ng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the",
        "ints that occur when engineering a RAG\nsystem? (section 5) We present an empirical experiment using\nthe BioASQ data set to report on potential failure points. The\nexperiment involved 15,000 documents and 1000 question\narXiv:2401.05856v1  [cs.SE]  11 Jan 2024\nCAIN 2024, April 2024, Lisbon, Portugal\nScott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\nand answer pairs. We indexed all documents then ran the\nqueries and stored the generated responses using GPT-4."
      ],
      "execution_time": 0.16794586181640625,
      "category": "challenges",
      "query_id": 23,
      "difficulty": "hard"
    },
    {
      "question": "How can RAG systems handle multi-hop reasoning?",
      "answer": "ng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the\n\nefront of research in the LLMs community.\nThe primary objective of this evaluation is to comprehend\nand optimize the performance of RAG models across diverse\napplication scenarios.This chapter will mainly introduce the\nmain downstream tasks of RAG, datasets, and how to evaluate\nRAG systems.\nA. Downstream Task\nThe core task of RAG remains Question Answering (QA),\nincluding\ntraditional\nsingle-hop/multi-hop\nQA,\nmultiple-\nchoice, domain-specific QA as well as long-form scenarios\nsuitable for RAG.\n\nefront of research in the LLMs community.\nThe primary objective of this evaluation is to comprehend\nand optimize the performance of RAG models across diverse\napplication scenarios.This chapter will mainly introduce the\nmain downstream tasks of RAG, datasets, and how to evaluate\nRAG systems.\nA. Downstream Task\nThe core task of RAG remains Question Answering (QA),\nincluding\ntraditional\nsingle-hop/multi-hop\nQA,\nmultiple-\nchoice, domain-specific QA as well as long-form scenarios\nsuitable for RAG.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_13",
        "2312.10997.pdf_chunk_148",
        "RAG_Survey_2023.pdf_chunk_148"
      ],
      "scores": [
        0.698106050491333,
        0.7528493404388428,
        0.7528493404388428
      ],
      "contexts": [
        "ng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the",
        "efront of research in the LLMs community.\nThe primary objective of this evaluation is to comprehend\nand optimize the performance of RAG models across diverse\napplication scenarios.This chapter will mainly introduce the\nmain downstream tasks of RAG, datasets, and how to evaluate\nRAG systems.\nA. Downstream Task\nThe core task of RAG remains Question Answering (QA),\nincluding\ntraditional\nsingle-hop/multi-hop\nQA,\nmultiple-\nchoice, domain-specific QA as well as long-form scenarios\nsuitable for RAG.",
        "efront of research in the LLMs community.\nThe primary objective of this evaluation is to comprehend\nand optimize the performance of RAG models across diverse\napplication scenarios.This chapter will mainly introduce the\nmain downstream tasks of RAG, datasets, and how to evaluate\nRAG systems.\nA. Downstream Task\nThe core task of RAG remains Question Answering (QA),\nincluding\ntraditional\nsingle-hop/multi-hop\nQA,\nmultiple-\nchoice, domain-specific QA as well as long-form scenarios\nsuitable for RAG."
      ],
      "execution_time": 0.1650681495666504,
      "category": "challenges",
      "query_id": 24,
      "difficulty": "hard"
    },
    {
      "question": "What are the scalability challenges in RAG systems?",
      "answer": "ng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the\n\ne present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_13",
        "2401.05856.pdf_chunk_17",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.4581676721572876,
        0.5837007164955139,
        0.6757925152778625
      ],
      "contexts": [
        "ng [8, 12] but how they relate\nand perform for a specific application context has to be discovered.\nIn this work we present the lessons learned and 7 failure points\narising from 3 case studies. The purpose of this paper is to provide\n1) a reference to practitioners and 2) to present a research road\nmap for RAG systems. To the best of our knowledge, we present\nthe first empirical insight into the challenges with creating robust\nRAG systems. As advances in LLMs continue to take place, the",
        "e present the lessons learned from three\ncase studies involving the implementation of a RAG system.\nThis presents the challenges faced and insights gained.\nContributions arising from this work include:\n• A catalogue of failure points (FP) that occur in RAG systems.\n• An experience report from 3 case studies of implementing a\nRAG system. Two currently running at Deakin University.\n• A research direction for RAG systems based on the lessons\nlearned from the 3 case studies.\n2\nRELATED WORK",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.15624308586120605,
      "category": "challenges",
      "query_id": 25,
      "difficulty": "medium"
    },
    {
      "question": "What is the optimal chunk size for RAG systems?",
      "answer": "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular\n\nEvaluating\nthe\nideal\nchunk\nsize\nfor\na\nrag\nsystem\nusing\nllamaindex,”\nhttps://www.llamaindex.ai/blog/\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\n2023.\n19\n[89] Langchain, “Recursively split by character,” https://python.langchain.\ncom/docs/modules/data connection/document transformers/recursive\ntext splitter, 2023.\n[90] S.\nYang,\n“Advanced\nrag\n01:\nSmall-to-\nbig\nretrieval,”\nhttps://towardsdatascience.com/\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\n\nEvaluating\nthe\nideal\nchunk\nsize\nfor\na\nrag\nsystem\nusing\nllamaindex,”\nhttps://www.llamaindex.ai/blog/\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\n2023.\n19\n[89] Langchain, “Recursively split by character,” https://python.langchain.\ncom/docs/modules/data connection/document transformers/recursive\ntext splitter, 2023.\n[90] S.\nYang,\n“Advanced\nrag\n01:\nSmall-to-\nbig\nretrieval,”\nhttps://towardsdatascience.com/\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_53",
        "2312.10997.pdf_chunk_244",
        "RAG_Survey_2023.pdf_chunk_244"
      ],
      "scores": [
        0.7968904376029968,
        0.7971855998039246,
        0.7971855998039246
      ],
      "contexts": [
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
        "Evaluating\nthe\nideal\nchunk\nsize\nfor\na\nrag\nsystem\nusing\nllamaindex,”\nhttps://www.llamaindex.ai/blog/\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\n2023.\n19\n[89] Langchain, “Recursively split by character,” https://python.langchain.\ncom/docs/modules/data connection/document transformers/recursive\ntext splitter, 2023.\n[90] S.\nYang,\n“Advanced\nrag\n01:\nSmall-to-\nbig\nretrieval,”\nhttps://towardsdatascience.com/\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.",
        "Evaluating\nthe\nideal\nchunk\nsize\nfor\na\nrag\nsystem\nusing\nllamaindex,”\nhttps://www.llamaindex.ai/blog/\nevaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5,\n2023.\n19\n[89] Langchain, “Recursively split by character,” https://python.langchain.\ncom/docs/modules/data connection/document transformers/recursive\ntext splitter, 2023.\n[90] S.\nYang,\n“Advanced\nrag\n01:\nSmall-to-\nbig\nretrieval,”\nhttps://towardsdatascience.com/\nadvanced-rag-01-small-to-big-retrieval-172181b396d4, 2023."
      ],
      "execution_time": 0.16334962844848633,
      "category": "implementation",
      "query_id": 26,
      "difficulty": "medium"
    },
    {
      "question": "How should chunk overlap be configured in RAG?",
      "answer": "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular\n\nai\n3https://www.langchain.com/\nC. Modular RAG\nThe modular RAG architecture advances beyond the for-\nmer two RAG paradigms, offering enhanced adaptability and\nversatility. It incorporates diverse strategies for improving its\ncomponents, such as adding a search module for similarity\nsearches and refining the retriever through fine-tuning. Inno-\nvations like restructured RAG modules [13] and rearranged\nRAG pipelines [14] have been introduced to tackle specific\nchallenges.\n\nai\n3https://www.langchain.com/\nC. Modular RAG\nThe modular RAG architecture advances beyond the for-\nmer two RAG paradigms, offering enhanced adaptability and\nversatility. It incorporates diverse strategies for improving its\ncomponents, such as adding a search module for similarity\nsearches and refining the retriever through fine-tuning. Inno-\nvations like restructured RAG modules [13] and rearranged\nRAG pipelines [14] have been introduced to tackle specific\nchallenges.",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_53",
        "2312.10997.pdf_chunk_40",
        "RAG_Survey_2023.pdf_chunk_40"
      ],
      "scores": [
        0.7912194728851318,
        0.9028121829032898,
        0.9028121829032898
      ],
      "contexts": [
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
        "ai\n3https://www.langchain.com/\nC. Modular RAG\nThe modular RAG architecture advances beyond the for-\nmer two RAG paradigms, offering enhanced adaptability and\nversatility. It incorporates diverse strategies for improving its\ncomponents, such as adding a search module for similarity\nsearches and refining the retriever through fine-tuning. Inno-\nvations like restructured RAG modules [13] and rearranged\nRAG pipelines [14] have been introduced to tackle specific\nchallenges.",
        "ai\n3https://www.langchain.com/\nC. Modular RAG\nThe modular RAG architecture advances beyond the for-\nmer two RAG paradigms, offering enhanced adaptability and\nversatility. It incorporates diverse strategies for improving its\ncomponents, such as adding a search module for similarity\nsearches and refining the retriever through fine-tuning. Inno-\nvations like restructured RAG modules [13] and rearranged\nRAG pipelines [14] have been introduced to tackle specific\nchallenges."
      ],
      "execution_time": 0.16842246055603027,
      "category": "implementation",
      "query_id": 27,
      "difficulty": "medium"
    },
    {
      "question": "What embedding models are best for RAG retrieval?",
      "answer": "tasius et al. 2021). These embeddings capture temporal and spatial features essential for effective\nretrieval and generation.\n3.4 Multimodal RAG Models: Multimodal RAG models integrate data from multiple modalities—text,\naudio, video, and images—to provide a more holistic approach to retrieval and generation tasks. Models\nlike Flamingo (Alayrac et al., 2022) integrate multiple modalities into a unified framework, enabling\nsimultaneous processing of text, images, and videos.\n\nevaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\npotential enhancements to tackle current challenges.\nThe paper unfolds as follows: Section II introduces the\nmain concept and current paradigms of RAG. The following\nthree sections explore core components—“Retrieval”, “Gen-\neration” and “Augmentation”, respectively. Section III focuses\non optimization methods in retrieval,including indexing, query\nand embedding optimization.\n\nevaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\npotential enhancements to tackle current challenges.\nThe paper unfolds as follows: Section II introduces the\nmain concept and current paradigms of RAG. The following\nthree sections explore core components—“Retrieval”, “Gen-\neration” and “Augmentation”, respectively. Section III focuses\non optimization methods in retrieval,including indexing, query\nand embedding optimization.",
      "relevant_chunks": 8,
      "sources": [
        "2410.12837.pdf_chunk_65",
        "2312.10997.pdf_chunk_18",
        "RAG_Survey_2023.pdf_chunk_18"
      ],
      "scores": [
        0.6050206422805786,
        0.627307653427124,
        0.627307653427124
      ],
      "contexts": [
        "tasius et al. 2021). These embeddings capture temporal and spatial features essential for effective\nretrieval and generation.\n3.4 Multimodal RAG Models: Multimodal RAG models integrate data from multiple modalities—text,\naudio, video, and images—to provide a more holistic approach to retrieval and generation tasks. Models\nlike Flamingo (Alayrac et al., 2022) integrate multiple modalities into a unified framework, enabling\nsimultaneous processing of text, images, and videos.",
        "evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\npotential enhancements to tackle current challenges.\nThe paper unfolds as follows: Section II introduces the\nmain concept and current paradigms of RAG. The following\nthree sections explore core components—“Retrieval”, “Gen-\neration” and “Augmentation”, respectively. Section III focuses\non optimization methods in retrieval,including indexing, query\nand embedding optimization.",
        "evaluation benchmarks and tools. Additionally,\nwe anticipate future directions for RAG, emphasizing\npotential enhancements to tackle current challenges.\nThe paper unfolds as follows: Section II introduces the\nmain concept and current paradigms of RAG. The following\nthree sections explore core components—“Retrieval”, “Gen-\neration” and “Augmentation”, respectively. Section III focuses\non optimization methods in retrieval,including indexing, query\nand embedding optimization."
      ],
      "execution_time": 0.17645525932312012,
      "category": "implementation",
      "query_id": 28,
      "difficulty": "medium"
    },
    {
      "question": "How do you choose the number of retrieved documents (top-k)?",
      "answer": "trieval, we precompute the embedding of\neach document d ∈D and construct FAISS index (Johnson\net al., 2019) over these embeddings.\n3.2. Input Reformulation\nThe retrieved top-k documents provide rich information\nabout the original input context x and can potentially help\nthe LM to make a better prediction. One simple way to\nincorporate the retrieved documents as part of the input to\nthe LM is to prepend x with all k documents. However, this\nsimple scheme is fundamentally restricted by the number\n\ncked queries, then it evaluates\nthe ∆RR of NeuDEF over K-NRM on each combination of document\nfields. The results on head queries are shown in Figure 2. Results\non torso and tail are similar and omitted due to space constraints.\nThe number of clicked queries per document follows a long\ntail distribution. The user preferences also heavily favor popular\ndocuments; documents with more click queries are more likely to\nbe relevant. NeuDEF performs better than K-NRM on all groups and\n\nch, we can additionally return the ranking order, instead of just the top-k set.\n16\nD. Global top-k\nGlobal top-k [28] is very similar to PT-k and ranks the object instances by their top-k probability, and\nthen takes the top-k of these. This approach has a runtime of O(n2k). The advantage here is that, unlike\nin PT-k, the number of results is ﬁxed, and there is no user-speciﬁed threshold parameter. Here we can",
      "relevant_chunks": 8,
      "sources": [
        "REPLUG_2023.pdf_chunk_29",
        "arxiv_1908.02938_2019.pdf_chunk_46",
        "0907.2868.pdf_chunk_142"
      ],
      "scores": [
        0.873246967792511,
        0.8958675861358643,
        0.9619942903518677
      ],
      "contexts": [
        "trieval, we precompute the embedding of\neach document d ∈D and construct FAISS index (Johnson\net al., 2019) over these embeddings.\n3.2. Input Reformulation\nThe retrieved top-k documents provide rich information\nabout the original input context x and can potentially help\nthe LM to make a better prediction. One simple way to\nincorporate the retrieved documents as part of the input to\nthe LM is to prepend x with all k documents. However, this\nsimple scheme is fundamentally restricted by the number",
        "cked queries, then it evaluates\nthe ∆RR of NeuDEF over K-NRM on each combination of document\nfields. The results on head queries are shown in Figure 2. Results\non torso and tail are similar and omitted due to space constraints.\nThe number of clicked queries per document follows a long\ntail distribution. The user preferences also heavily favor popular\ndocuments; documents with more click queries are more likely to\nbe relevant. NeuDEF performs better than K-NRM on all groups and",
        "ch, we can additionally return the ranking order, instead of just the top-k set.\n16\nD. Global top-k\nGlobal top-k [28] is very similar to PT-k and ranks the object instances by their top-k probability, and\nthen takes the top-k of these. This approach has a runtime of O(n2k). The advantage here is that, unlike\nin PT-k, the number of results is ﬁxed, and there is no user-speciﬁed threshold parameter. Here we can"
      ],
      "execution_time": 0.16491913795471191,
      "category": "implementation",
      "query_id": 29,
      "difficulty": "medium"
    },
    {
      "question": "What vector databases are commonly used for RAG?",
      "answer": "LLM.\nGraphRAG is available as open-source software at https://github.com/microsoft/graphrag. In ad-\ndition, versions of the GraphRAG approach are also available as extensions to multiple open-\nsource libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu-\nlaGraph (NebulaGraph, 2024), and Neo4J (Neo4J, 2024).\n2\nBackground\n2.1\nRAG Approaches and Systems\nRAG generally refers to any system where a user query is used to retrieve relevant information from\n\nRAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2404.16130.pdf_chunk_15",
        "2404.16130.pdf_chunk_16",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.6979588270187378,
        0.7282238602638245,
        0.7508061528205872
      ],
      "contexts": [
        "LLM.\nGraphRAG is available as open-source software at https://github.com/microsoft/graphrag. In ad-\ndition, versions of the GraphRAG approach are also available as extensions to multiple open-\nsource libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu-\nlaGraph (NebulaGraph, 2024), and Neo4J (Neo4J, 2024).\n2\nBackground\n2.1\nRAG Approaches and Systems\nRAG generally refers to any system where a user query is used to retrieve relevant information from",
        "RAG generally refers to any system where a user query is used to retrieve relevant information from\nexternal data sources, whereupon this information is incorporated into the generation of a response\nto the query by an LLM (or other generative AI model, such as a multi-media model). The query and\nretrieved records populate a prompt template, which is then passed to the LLM (Ram et al., 2023).\nRAG is ideal when the total number of records in a data source is too large to include in a single",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.164215087890625,
      "category": "implementation",
      "query_id": 30,
      "difficulty": "easy"
    },
    {
      "question": "Compare BM25 and dense vector retrieval methods",
      "answer": "s limitation, BM25 is still widely used because of its simplicity and efficiency. BM25 is effective\nfor tasks involving simpler, keyword-based queries, although more modern retrieval models like DPR tend\nto outperform it in semantically complex tasks.\n2.2.2 Dense Passage Retrieval (DPR)\nDense Passage Retrieval (DPR), introduced by Karpukhin et al. (2020), represents a more modern\napproach to information retrieval. It uses a dense vector space in which both the query and the\n\nnal corpus.\nEffective retrieval ensures that the model's output is grounded in accurate information. Several retrieval\nmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticated\ntechniques like Dense Passage Retrieval (DPR).\n2.2.1 BM25\nBM25 is a well-established information retrieval algorithm that uses the term frequency-inverse document\nfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25\n\nfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25\nremains a strong baseline for many modern retrieval systems, including those used in RAG models.\nBM25 calculates the relevance score of a document based on how frequently a query term appears in the\ndocument while adjusting for the document's length and the frequency of the term across the corpus\n(Robertson et. al. 2009).",
      "relevant_chunks": 8,
      "sources": [
        "2410.12837.pdf_chunk_44",
        "2410.12837.pdf_chunk_41",
        "2410.12837.pdf_chunk_42"
      ],
      "scores": [
        0.686732292175293,
        0.7520180344581604,
        0.7857177257537842
      ],
      "contexts": [
        "s limitation, BM25 is still widely used because of its simplicity and efficiency. BM25 is effective\nfor tasks involving simpler, keyword-based queries, although more modern retrieval models like DPR tend\nto outperform it in semantically complex tasks.\n2.2.2 Dense Passage Retrieval (DPR)\nDense Passage Retrieval (DPR), introduced by Karpukhin et al. (2020), represents a more modern\napproach to information retrieval. It uses a dense vector space in which both the query and the",
        "nal corpus.\nEffective retrieval ensures that the model's output is grounded in accurate information. Several retrieval\nmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticated\ntechniques like Dense Passage Retrieval (DPR).\n2.2.1 BM25\nBM25 is a well-established information retrieval algorithm that uses the term frequency-inverse document\nfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25",
        "frequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25\nremains a strong baseline for many modern retrieval systems, including those used in RAG models.\nBM25 calculates the relevance score of a document based on how frequently a query term appears in the\ndocument while adjusting for the document's length and the frequency of the term across the corpus\n(Robertson et. al. 2009)."
      ],
      "execution_time": 0.16564631462097168,
      "category": "comparison",
      "query_id": 31,
      "difficulty": "medium"
    },
    {
      "question": "When should you use Naive RAG vs Advanced RAG?",
      "answer": "rize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite\nRAG method are cost-effective and surpass the performance\nof the native LLM, they also exhibit several limitations.\nThe development of Advanced RAG and Modular RAG is\na response to these specific shortcomings in Naive RAG.\nA. Naive RAG\nThe Naive RAG research paradigm represents the earli-\nest methodology, which gained prominence shortly after the\n3\nFig. 2.\n\nrize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite\nRAG method are cost-effective and surpass the performance\nof the native LLM, they also exhibit several limitations.\nThe development of Advanced RAG and Modular RAG is\na response to these specific shortcomings in Naive RAG.\nA. Naive RAG\nThe Naive RAG research paradigm represents the earli-\nest methodology, which gained prominence shortly after the\n3\nFig. 2.\n\nnovations.\nOur contributions are as follows:\n• In this survey, we present a thorough and systematic\nreview of the state-of-the-art RAG methods, delineating\nits evolution through paradigms including naive RAG,\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024\n2\nFig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_22",
        "RAG_Survey_2023.pdf_chunk_22",
        "RAG_Survey_2023.pdf_chunk_14"
      ],
      "scores": [
        0.46925216913223267,
        0.46925216913223267,
        0.6285815238952637
      ],
      "contexts": [
        "rize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite\nRAG method are cost-effective and surpass the performance\nof the native LLM, they also exhibit several limitations.\nThe development of Advanced RAG and Modular RAG is\na response to these specific shortcomings in Naive RAG.\nA. Naive RAG\nThe Naive RAG research paradigm represents the earli-\nest methodology, which gained prominence shortly after the\n3\nFig. 2.",
        "rize it into three stages: Naive RAG, Advanced\nRAG, and Modular RAG, as showed in Figure 3. Despite\nRAG method are cost-effective and surpass the performance\nof the native LLM, they also exhibit several limitations.\nThe development of Advanced RAG and Modular RAG is\na response to these specific shortcomings in Naive RAG.\nA. Naive RAG\nThe Naive RAG research paradigm represents the earli-\nest methodology, which gained prominence shortly after the\n3\nFig. 2.",
        "novations.\nOur contributions are as follows:\n• In this survey, we present a thorough and systematic\nreview of the state-of-the-art RAG methods, delineating\nits evolution through paradigms including naive RAG,\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024\n2\nFig. 1. Technology tree of RAG research. The stages of involving RAG mainly include pre-training, fine-tuning, and inference. With the emergence of LLMs,"
      ],
      "execution_time": 0.17474079132080078,
      "category": "comparison",
      "query_id": 32,
      "difficulty": "medium"
    },
    {
      "question": "Compare Self-RAG with Corrective RAG approaches",
      "answer": "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nlated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_168"
      ],
      "scores": [
        0.633921205997467,
        0.633921205997467,
        0.6497595906257629
      ],
      "contexts": [
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "lated work, are traditional measures\nand do not yet represent a mature or standardized approach for\nquantifying RAG evaluation aspects. Custom metrics tailored\nto the nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\nD. Evaluation Benchmarks and Tools\nA series of benchmark tests and tools have been proposed\nto facilitate the evaluation of RAG.These instruments furnish\nquantitative metrics that not only gauge RAG model perfor-"
      ],
      "execution_time": 0.17084908485412598,
      "category": "comparison",
      "query_id": 33,
      "difficulty": "hard"
    },
    {
      "question": "What are the trade-offs between hybrid and pure dense retrieval?",
      "answer": "hitectures (Vaswani et al. 2017), offered fluency and creativity but often lacked factual\naccuracy.\nThe development of hybrid systems combining retrieval and generation began to gain momentum as\nresearchers recognized the complementary strengths of both approaches. Early efforts in hybrid modeling\ncan be traced back to works like DrQA (Chen et al. 2017), which employed retrieval techniques to fetch\nrelevant documents for question-answering tasks.\n\ne models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,\n\ne models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,",
      "relevant_chunks": 8,
      "sources": [
        "2410.12837.pdf_chunk_16",
        "2312.10997.pdf_chunk_82",
        "RAG_Survey_2023.pdf_chunk_82"
      ],
      "scores": [
        0.8987884521484375,
        0.9352141618728638,
        0.9352141618728638
      ],
      "contexts": [
        "hitectures (Vaswani et al. 2017), offered fluency and creativity but often lacked factual\naccuracy.\nThe development of hybrid systems combining retrieval and generation began to gain momentum as\nresearchers recognized the complementary strengths of both approaches. Early efforts in hybrid modeling\ncan be traced back to works like DrQA (Chen et al. 2017), which employed retrieval techniques to fetch\nrelevant documents for question-answering tasks.",
        "e models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,",
        "e models in downstream tasks [50],\n[87]. On the other hand, fine-grained retrieval unit granularity\nincreases the burden of retrieval and does not guarantee seman-\ntic integrity and meeting the required knowledge. Choosing\n8\nthe appropriate retrieval granularity during inference can be\na simple and effective strategy to improve the retrieval and\ndownstream task performance of dense retrievers.\nIn text, retrieval granularity ranges from fine to coarse,"
      ],
      "execution_time": 0.1746833324432373,
      "category": "comparison",
      "query_id": 34,
      "difficulty": "medium"
    },
    {
      "question": "Compare single-stage vs multi-stage retrieval in RAG",
      "answer": "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\nly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.\n\ndaptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_34",
        "RAG_Survey_2023.pdf_chunk_51"
      ],
      "scores": [
        0.5153828859329224,
        0.5153828859329224,
        0.5573524832725525
      ],
      "contexts": [
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "ly, it incorporates several optimization\nmethods to streamline the retrieval process [8].\n4\nFig. 3.\nComparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\nAdvanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\nchain-like structure.",
        "daptive retrieval through techniques such as\nFLARE [24] and Self-RAG [25]. This approach transcends\nthe fixed RAG retrieval process by evaluating the necessity\nof retrieval based on different scenarios. Another benefit of\na flexible architecture is that the RAG system can more\neasily integrate with other technologies (such as fine-tuning\nor reinforcement learning) [26]. For example, this can involve\nfine-tuning the retriever for better retrieval results, fine-tuning"
      ],
      "execution_time": 0.16851139068603516,
      "category": "comparison",
      "query_id": 35,
      "difficulty": "hard"
    },
    {
      "question": "How can we improve retrieval quality in RAG?",
      "answer": "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.\n\nND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_11",
        "RAG_Survey_2023.pdf_chunk_11",
        "2401.05856.pdf_chunk_53"
      ],
      "scores": [
        0.5328013896942139,
        0.5328013896942139,
        0.6269738674163818
      ],
      "contexts": [
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ng out the RAG process and charting\nits evolution and anticipated future paths, with a focus on the\nintegration of RAG within LLMs. This paper considers both\ntechnical paradigms and research methods, summarizing three\nmain research paradigms from over 100 RAG studies, and\nanalyzing key technologies in the core stages of “Retrieval,”\n“Generation,” and “Augmentation.” On the other hand, current\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG.",
        "ND FUTURE RESEARCH\nDIRECTIONS\nThe lessons learned from the three case studies are shown in Table 2.\nWe present our findings for the research question: What are the\nkey considerations when engineering a RAG system? Based on our\ntakeaways we identified multiple potential research areas linked to\nRAG as follows:\n6.1\nChunking and Embeddings\nChunking documents sounds trivial. However, the quality of chunk-\ning affects the retrieval process in many ways and in particular"
      ],
      "execution_time": 0.17361831665039062,
      "category": "optimization",
      "query_id": 36,
      "difficulty": "medium"
    },
    {
      "question": "What techniques reduce hallucinations in RAG systems?",
      "answer": "LM\nhallucinations in depth (§3), followed by a review of various strategies and benchmarks employed\nfor the reliable detection of hallucinations in LLMs (§4). We then detail a spectrum of approaches\ndesigned to mitigate these hallucinations (§5). Concluding, we delve into the challenges faced by\ncurrent RAG systems (§6) and delineate potential pathways for forthcoming research (§7).\n2\nDEFINITIONS\nFor the sake of a comprehensive understanding of hallucinations in LLMs, we commence with a\n\nes,\nevaluation benchmarks, and mitigation strategies. However, our survey sets itself apart through\na unique taxonomy and organizational structure. We present a detailed, layered classification of\nhallucinations and conduct a more comprehensive analysis of the causes of hallucinations. Crucially,\nour proposed mitigation strategies are directly tied to these causes, offering a targeted and coherent\nframework for addressing LLM hallucinations.\nOrganization of this Survey.\n\ne present a comprehensive review of contemporary methods aimed at mitigating\nhallucinations in LLMs. Drawing from insights discussed in Hallucination Causes (§3), we systemat-\nically categorize these methods based on the underlying causes of hallucinations. Specifically, we\nfocus on approaches addressing Data-related Hallucinations (§5.1), Training-related Hallucinations\n(§5.2) and Inference-related Hallucinations (§5.3), each offering tailored solutions to tackle specific",
      "relevant_chunks": 8,
      "sources": [
        "2311.05232.pdf_chunk_32",
        "2311.05232.pdf_chunk_30",
        "2311.05232.pdf_chunk_205"
      ],
      "scores": [
        0.4732256233692169,
        0.6735022664070129,
        0.7456938028335571
      ],
      "contexts": [
        "LM\nhallucinations in depth (§3), followed by a review of various strategies and benchmarks employed\nfor the reliable detection of hallucinations in LLMs (§4). We then detail a spectrum of approaches\ndesigned to mitigate these hallucinations (§5). Concluding, we delve into the challenges faced by\ncurrent RAG systems (§6) and delineate potential pathways for forthcoming research (§7).\n2\nDEFINITIONS\nFor the sake of a comprehensive understanding of hallucinations in LLMs, we commence with a",
        "es,\nevaluation benchmarks, and mitigation strategies. However, our survey sets itself apart through\na unique taxonomy and organizational structure. We present a detailed, layered classification of\nhallucinations and conduct a more comprehensive analysis of the causes of hallucinations. Crucially,\nour proposed mitigation strategies are directly tied to these causes, offering a targeted and coherent\nframework for addressing LLM hallucinations.\nOrganization of this Survey.",
        "e present a comprehensive review of contemporary methods aimed at mitigating\nhallucinations in LLMs. Drawing from insights discussed in Hallucination Causes (§3), we systemat-\nically categorize these methods based on the underlying causes of hallucinations. Specifically, we\nfocus on approaches addressing Data-related Hallucinations (§5.1), Training-related Hallucinations\n(§5.2) and Inference-related Hallucinations (§5.3), each offering tailored solutions to tackle specific"
      ],
      "execution_time": 0.17801809310913086,
      "category": "optimization",
      "query_id": 37,
      "difficulty": "hard"
    },
    {
      "question": "How can we optimize RAG for low-latency applications?",
      "answer": "to shine a light on what issues\nengineers will face and what software engineering research is nec-\nessary to realise solutions with the current state-of-the-art RAG\nsystems.\nEmerging work has looked at benchmarking RAG systems [3]\nbut not at the failures occurring during implementation. Software\nengineering research has investigated the use of RAG systems for\ncode-related tasks [15]. However, the application of RAG systems\nis broader than software engineering tasks. This paper comple-\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
      "relevant_chunks": 8,
      "sources": [
        "2401.05856.pdf_chunk_20",
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12"
      ],
      "scores": [
        0.8399336338043213,
        0.8541632294654846,
        0.8541632294654846
      ],
      "contexts": [
        "to shine a light on what issues\nengineers will face and what software engineering research is nec-\nessary to realise solutions with the current state-of-the-art RAG\nsystems.\nEmerging work has looked at benchmarking RAG systems [3]\nbut not at the failures occurring during implementation. Software\nengineering research has investigated the use of RAG systems for\ncode-related tasks [15]. However, the application of RAG systems\nis broader than software engineering tasks. This paper comple-",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and"
      ],
      "execution_time": 0.17499947547912598,
      "category": "optimization",
      "query_id": 38,
      "difficulty": "hard"
    },
    {
      "question": "What is context compression in RAG and why is it useful?",
      "answer": "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during\n\nlely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during\n\nhe progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_174",
        "RAG_Survey_2023.pdf_chunk_174",
        "RAG_Survey_2023.pdf_chunk_3"
      ],
      "scores": [
        0.6873837113380432,
        0.6873837113380432,
        0.7935672998428345
      ],
      "contexts": [
        "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during",
        "lely relying on long context remains a\nblack box. Conversely, the expansion of context provides new\nopportunities for the development of RAG, enabling it to\naddress more complex problems and integrative or summary\nquestions that require reading a large amount of material to\nanswer [49]. Developing new RAG methods in the context of\nsuper-long contexts is one of the future research trends.\nB. RAG Robustness\nThe presence of noise or contradictory information during",
        "he progression of RAG paradigms, encompassing\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\nIt meticulously scrutinizes the tripartite foundation of RAG\nframeworks, which includes the retrieval, the generation and the\naugmentation techniques. The paper highlights the state-of-the-\nart technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG\nsystems. Furthermore, this paper introduces up-to-date evalua-"
      ],
      "execution_time": 0.17783713340759277,
      "category": "optimization",
      "query_id": 39,
      "difficulty": "hard"
    },
    {
      "question": "How does prompt engineering affect RAG quality?",
      "answer": "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nresearch tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and\n\nmated tools like RAGAS [164],\nARES [165], and TruLens8 employ LLMs to adjudicate the\nquality scores. These tools and benchmarks collectively form\na robust framework for the systematic evaluation of RAG\nmodels, as summarized in Table IV.\nVII. DISCUSSION AND FUTURE PROSPECTS\nDespite the considerable progress in RAG technology, sev-\neral challenges persist that warrant in-depth research.This\nchapter will mainly introduce the current challenges and future\nresearch directions faced by RAG.\nA.",
      "relevant_chunks": 8,
      "sources": [
        "2312.10997.pdf_chunk_12",
        "RAG_Survey_2023.pdf_chunk_12",
        "2312.10997.pdf_chunk_170"
      ],
      "scores": [
        0.7330548763275146,
        0.7330548763275146,
        0.7456611394882202
      ],
      "contexts": [
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "research tends to focus more on methods, lacking analysis and\nsummarization of how to evaluate RAG. This paper compre-\nhensively reviews the downstream tasks, datasets, benchmarks,\nand evaluation methods applicable to RAG. Overall, this\npaper sets out to meticulously compile and categorize the\nfoundational technical concepts, historical progression, and\nthe spectrum of RAG methodologies and applications that\nhave emerged post-LLMs. It is designed to equip readers and",
        "mated tools like RAGAS [164],\nARES [165], and TruLens8 employ LLMs to adjudicate the\nquality scores. These tools and benchmarks collectively form\na robust framework for the systematic evaluation of RAG\nmodels, as summarized in Table IV.\nVII. DISCUSSION AND FUTURE PROSPECTS\nDespite the considerable progress in RAG technology, sev-\neral challenges persist that warrant in-depth research.This\nchapter will mainly introduce the current challenges and future\nresearch directions faced by RAG.\nA."
      ],
      "execution_time": 0.1758272647857666,
      "category": "optimization",
      "query_id": 40,
      "difficulty": "medium"
    }
  ],
  "metrics": {
    "average_execution_time": 0.1752719020843506,
    "average_top_score": 0.6516192531585694,
    "total_queries": 50
  }
}